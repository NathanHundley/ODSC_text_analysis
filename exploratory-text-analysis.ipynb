{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Text Analysis in Python using spaCy and textacy\n",
    "\n",
    "Workshop for Open Data Science Conference East 2021 <br />\n",
    "[Workshop materials](https://github.com/csbailey5t/ODSC_text_analysis)\n",
    "\n",
    "Scott Bailey <br/>\n",
    "Digital Research and Scholarship Librarian <br/>\n",
    "Copyright and Digital Scholarship Center <br/>\n",
    "NC State University Libraries\n",
    "\n",
    "## Outline\n",
    "1. Intro and overview of NLP libraries\n",
    "2. Document-level analysis <br/>\n",
    "    a. Tokenization <br/>\n",
    "    b. Cleaning text data <br />\n",
    "    c. Part-of-speech tagging <br/>\n",
    "    d. Named entity recognition <br/>\n",
    "    e. Similarity vectors <br/>\n",
    "    f. Rule-based matching <br />\n",
    "3. Scaling up to corpus-level analysis\n",
    "4. Further resources for spaCy\n",
    "\n",
    "## What do we mean by \"exploratory text analysis?\"\n",
    "- How clean are the data?\n",
    "- What methods do the data support?\n",
    "- Project scoping \n",
    "- Research question refinement\n",
    "- Iterative research \n",
    "\n",
    "## A quick(!) overview of NLP-related libraries in Python\n",
    "- [nltk](https://www.nltk.org/)\n",
    "- [gensim](https://radimrehurek.com/gensim/)\n",
    "- [scikit-learn](https://scikit-learn.org/stable/)\n",
    "- [stanza/corenlp](https://stanfordnlp.github.io/stanza/)\n",
    "- [spaCy](https://spacy.io/)\n",
    "- [huggingface transformers - pytorch and tensorflow](https://github.com/huggingface/transformers)\n",
    "\n",
    "### Why spaCy and textacy?\n",
    "\n",
    "SpaCy is an opinionated, performant NLP library that does a lot of the work for you while revealing where you might need to do more custom refinement or model building. Textacy builds smoothly on spaCy to add corpus analysis and common information retrieval methods.\n",
    "\n",
    "## Questions during the workshop\n",
    "\n",
    "During the workshop, please do ask questions by way of the chat. I'll be keeping an eye on that, and will answer questions as we go if I can. I'll also give some time during and after the workshop when folks can unmute and ask questions. \n",
    "\n",
    "## Jupyter Notebooks, Google Colab, and Binder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if working in Google Colab or Binder\n",
    "# If working locally, install dependencies per requirements.txt\n",
    "# !pip install textacy\n",
    "# !python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import glob\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate ways to load the model, with the first working consistently in Colab\n",
    "# nlp = en_core_web_md.load()\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://en.wikipedia.org/wiki/Data_science\n",
    "sample_text = \"\"\"Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. Data science is related to data mining, machine learning and big data.\n",
    "\n",
    "Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyze actual phenomena\" with data. It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. Turing award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "science\n",
      "is\n",
      "an\n",
      "inter\n",
      "-\n",
      "disciplinary\n",
      "field\n",
      "that\n",
      "uses\n",
      "scientific\n",
      "methods\n",
      ",\n",
      "processes\n",
      ",\n",
      "algorithms\n",
      "and\n",
      "systems\n",
      "to\n",
      "extract\n"
     ]
    }
   ],
   "source": [
    "for word in doc[:20]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science\n",
      "an inter-disciplinary field\n",
      "scientific methods\n",
      "processes\n",
      "algorithms\n",
      "systems\n",
      "knowledge\n",
      "insights\n",
      "structured and unstructured data\n",
      "knowledge\n",
      "actionable insights\n",
      "data\n",
      "a broad range\n",
      "application domains\n",
      "Data science\n",
      "data mining\n",
      "machine learning\n",
      "big data\n",
      "Data science\n",
      "a \"concept\n",
      "unify statistics\n",
      "data analysis\n",
      "informatics\n",
      "their related methods\n",
      "order\n",
      "actual phenomena\n",
      "data\n",
      "It\n",
      "techniques\n",
      "theories\n",
      "many fields\n",
      "the context\n",
      "mathematics\n",
      "statistics\n",
      "computer science\n",
      "information science\n",
      "domain knowledge\n",
      "Turing award winner\n",
      "Jim Gray\n",
      "data science\n",
      "a \"fourth paradigm\n",
      "science\n",
      "everything\n",
      "science\n",
      "the impact\n",
      "information technology\n",
      "the data deluge\n"
     ]
    }
   ],
   "source": [
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains.\n",
      "Data science is related to data mining, machine learning and big data.\n",
      "\n",
      "\n",
      "Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyze actual phenomena\" with data.\n",
      "It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.\n",
      "Turing award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big False\n",
      "data False\n",
      "\n",
      "\n",
      " False\n",
      "Data False\n",
      "science False\n",
      "is False\n",
      "a False\n",
      "concept False\n",
      "to False\n",
      "unify False\n",
      "statistics False\n",
      "data False\n",
      "analysis False\n",
      "informatics False\n",
      "and False\n",
      "their False\n",
      "related False\n",
      "methods False\n",
      "in False\n",
      "order False\n",
      "to False\n",
      "understand False\n",
      "and False\n",
      "analyze False\n",
      "actual False\n",
      "phenomena False\n",
      "with False\n",
      "data False\n",
      "It False\n",
      "uses False\n",
      "techniques False\n",
      "and False\n",
      "theories False\n",
      "drawn False\n",
      "from False\n",
      "many False\n",
      "fields False\n",
      "within False\n",
      "the False\n",
      "context False\n",
      "of False\n",
      "mathematics False\n",
      "statistics False\n",
      "computer False\n",
      "science False\n",
      "information False\n",
      "science False\n",
      "and False\n",
      "domain False\n",
      "knowledge False\n"
     ]
    }
   ],
   "source": [
    "# One of the common things we do in text analysis is to remove punctuation\n",
    "no_punct = [token for token in doc if token.is_punct == False]\n",
    "for token in no_punct[50:100]:\n",
    "  print(token.text, token.is_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big\n",
      "data\n",
      "Data\n",
      "science\n",
      "is\n",
      "a\n",
      "concept\n",
      "to\n",
      "unify\n",
      "statistics\n",
      "data\n",
      "analysis\n",
      "informatics\n",
      "and\n",
      "their\n",
      "related\n",
      "methods\n",
      "in\n",
      "order\n",
      "to\n",
      "understand\n",
      "and\n",
      "analyze\n",
      "actual\n",
      "phenomena\n",
      "with\n",
      "data\n",
      "It\n",
      "uses\n",
      "techniques\n",
      "and\n",
      "theories\n",
      "drawn\n",
      "from\n",
      "many\n",
      "fields\n",
      "within\n",
      "the\n",
      "context\n",
      "of\n",
      "mathematics\n",
      "statistics\n",
      "computer\n",
      "science\n",
      "information\n",
      "science\n",
      "and\n",
      "domain\n",
      "knowledge\n",
      "Turing\n"
     ]
    }
   ],
   "source": [
    "# This has worked, but left in new line characters and spaces\n",
    "no_punct_or_space = [token for token in doc if token.is_punct == False and token.is_space == False]\n",
    "for token in no_punct_or_space[50:100]:\n",
    "  print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['data',\n 'science',\n 'is',\n 'an',\n 'inter',\n 'disciplinary',\n 'field',\n 'that',\n 'uses',\n 'scientific',\n 'methods',\n 'processes',\n 'algorithms',\n 'and',\n 'systems',\n 'to',\n 'extract',\n 'knowledge',\n 'and',\n 'insights',\n 'from',\n 'structured',\n 'and',\n 'unstructured',\n 'data',\n 'and',\n 'apply',\n 'knowledge',\n 'and',\n 'actionable']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's say we also want to remove numbers, and lowercase everything\n",
    "lower_alpha = [token.lower_ for token in no_punct_or_space if token.is_alpha == True]\n",
    "lower_alpha[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other common bit of preprocessing is to remove stopwords, that is, the common words in a language that don't convey the information that we are looking for in our analysis. For example, if we looked for the most common words in a text, we would want to remove stopwords so that we don't only get words such as 'a,' 'the,' and 'and.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['data',\n 'science',\n 'inter',\n 'disciplinary',\n 'field',\n 'uses',\n 'scientific',\n 'methods',\n 'processes',\n 'algorithms',\n 'systems',\n 'extract',\n 'knowledge',\n 'insights',\n 'structured',\n 'unstructured',\n 'data',\n 'apply',\n 'knowledge',\n 'actionable',\n 'insights',\n 'data',\n 'broad',\n 'range',\n 'application',\n 'domains',\n 'data',\n 'science',\n 'related',\n 'data']"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = [token.lower_ for token in no_punct_or_space if token.is_alpha == True and token.is_stop == False]\n",
    "clean[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this piece, we've used spaCy's built in stopword list, which is used to create the property `is_stop` for each token. There's a good chance you would want to create custom stopwords lists though, especially if you're working with historical text or really domain-specific text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['science',\n 'is',\n 'an',\n 'inter',\n '-',\n 'disciplinary',\n 'field',\n 'that',\n 'uses',\n 'scientific',\n 'methods',\n ',',\n 'processes',\n ',',\n 'and',\n 'systems',\n 'to',\n 'extract',\n 'knowledge',\n 'and',\n 'insights',\n 'from',\n 'structured',\n 'and',\n 'unstructured',\n ',',\n 'and',\n 'apply',\n 'knowledge',\n 'and',\n 'actionable',\n 'insights',\n 'from',\n 'across',\n 'a',\n 'broad',\n 'range',\n 'of',\n 'application',\n 'domains',\n '.',\n 'science',\n 'is',\n 'related',\n 'to',\n 'mining',\n ',',\n 'machine',\n 'learning',\n 'and',\n 'big',\n '.',\n '\\n\\n',\n 'science',\n 'is',\n 'a',\n '\"',\n 'concept',\n 'to',\n 'unify',\n 'statistics',\n ',',\n 'analysis',\n ',',\n 'informatics',\n ',',\n 'and',\n 'their',\n 'related',\n 'methods',\n '\"',\n 'in',\n 'order',\n 'to',\n '\"',\n 'understand',\n 'and',\n 'analyze',\n 'actual',\n 'phenomena',\n '\"',\n 'with',\n '.',\n 'it',\n 'uses',\n 'techniques',\n 'and',\n 'theories',\n 'drawn',\n 'from',\n 'many',\n 'fields',\n 'within',\n 'the',\n 'context',\n 'of',\n 'mathematics',\n ',',\n 'statistics',\n ',',\n 'computer',\n 'science',\n ',',\n 'information',\n 'science',\n ',',\n 'and',\n 'domain',\n 'knowledge',\n '.',\n 'turing',\n 'award',\n 'winner',\n 'jim',\n 'gray',\n 'imagined',\n 'science',\n 'as',\n 'a',\n '\"',\n 'fourth',\n 'paradigm',\n '\"',\n 'of',\n 'science',\n '(',\n 'empirical',\n ',',\n 'theoretical',\n ',',\n 'computational',\n 'and',\n 'now',\n '-',\n 'driven',\n ')',\n 'and',\n 'asserted',\n 'that',\n '\"',\n 'everything',\n 'about',\n 'science',\n 'is',\n 'changing',\n 'because',\n 'of',\n 'the',\n 'impact',\n 'of',\n 'information',\n 'technology',\n '\"',\n 'and',\n 'the',\n 'deluge',\n '.']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll just pick a couple of words we know are in the example\n",
    "custom_stopwords = [\"data\", \"algorithms\"]\n",
    "\n",
    "custom_clean = [token.lower_ for token in doc if token.lower_ not in custom_stopwords]\n",
    "custom_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a list of lower-cased tokens that doesn't contain punctuation, white-space, numbers, or stopwords. Depending on our analysis, we may or may not want to do this much cleaning. But, it is good to understand how much we can do just with spaCy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we can break apart the document and filter it now, it's a good time to start counting things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in document:  170\n",
      "Number of tokens in cleaned document:  89\n",
      "Number of unique tokens in cleaned document:  63\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens in document: \", len(doc))\n",
    "print(\"Number of tokens in cleaned document: \", len(clean))\n",
    "print(\"Number of unique tokens in cleaned document: \", len(set(clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "5"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of sentences\n",
    "len(list(doc.sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[(',', 13),\n ('and', 13),\n ('data', 12),\n ('science', 8),\n ('\"', 8),\n ('of', 5),\n ('.', 5),\n ('is', 4),\n ('to', 4),\n ('knowledge', 3),\n ('from', 3),\n ('a', 3),\n ('the', 3),\n ('-', 2),\n ('that', 2),\n ('uses', 2),\n ('methods', 2),\n ('insights', 2),\n ('related', 2),\n ('statistics', 2)]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count all lower-cased tokens\n",
    "full_counter = Counter([token.lower_ for token in doc])\n",
    "full_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('data', 12),\n ('science', 8),\n ('knowledge', 3),\n ('uses', 2),\n ('methods', 2),\n ('insights', 2),\n ('related', 2),\n ('statistics', 2),\n ('information', 2),\n ('inter', 1),\n ('disciplinary', 1),\n ('field', 1),\n ('scientific', 1),\n ('processes', 1),\n ('algorithms', 1),\n ('systems', 1),\n ('extract', 1),\n ('structured', 1),\n ('unstructured', 1),\n ('apply', 1)]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count cleaned tokens\n",
    "cleaned_counter = Counter(clean)\n",
    "cleaned_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity\n",
    "\n",
    "In the cell below, write code to find the five most common noun chunks in the original doc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data NOUN\n",
      "science NOUN\n",
      "is AUX\n",
      "an DET\n",
      "inter ADJ\n",
      "- ADJ\n",
      "disciplinary ADJ\n",
      "field NOUN\n",
      "that DET\n",
      "uses VERB\n",
      "scientific ADJ\n",
      "methods NOUN\n",
      ", PUNCT\n",
      "processes NOUN\n",
      ", PUNCT\n",
      "algorithms NOUN\n",
      "and CCONJ\n",
      "systems NOUN\n",
      "to PART\n",
      "extract VERB\n"
     ]
    }
   ],
   "source": [
    "# Coarse grained UPOS: https://universaldependencies.org/docs/u/pos/\n",
    "for token in doc[:20]:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data NN\n",
      "science NN\n",
      "is VBZ\n",
      "an DT\n",
      "inter JJ\n",
      "- JJ\n",
      "disciplinary JJ\n",
      "field NN\n",
      "that WDT\n",
      "uses VBZ\n",
      "scientific JJ\n",
      "methods NNS\n",
      ", ,\n",
      "processes NNS\n",
      ", ,\n",
      "algorithms NNS\n",
      "and CC\n",
      "systems NNS\n",
      "to TO\n",
      "extract VB\n"
     ]
    }
   ],
   "source": [
    "# Fine-grained POS, Penn Treebank: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "for token in doc[:20]:\n",
    "    print(token.text, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'determiner'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not sure what those tags are? Try spaCy's explain function\n",
    "spacy.explain(\"DT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[uses,\n extract,\n apply,\n related,\n understand,\n analyze,\n uses,\n drawn,\n imagined,\n driven,\n asserted,\n changing]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect tokens by part of speech\n",
    "verbs = [token for token in doc if token.pos_ == \"VERB\"]\n",
    "verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[methods,\n processes,\n algorithms,\n systems,\n insights,\n data,\n insights,\n data,\n domains,\n data,\n data,\n statistics,\n data,\n informatics,\n methods,\n phenomena,\n data,\n techniques,\n theories,\n fields,\n mathematics,\n statistics,\n data]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect plural nouns\n",
    "nouns_pl = [token for token in doc if token.tag_ == \"NNS\" or token.tag_ == \"NNPS\"]\n",
    "nouns_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency tree visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains."
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_sentence = list(doc.sents)[0]\n",
    "single_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data compound\n",
      "science nsubj\n",
      "is ROOT\n",
      "an det\n",
      "inter dep\n",
      "- dep\n",
      "disciplinary amod\n",
      "field attr\n",
      "that nsubj\n",
      "uses relcl\n",
      "scientific amod\n",
      "methods dobj\n",
      ", punct\n",
      "processes conj\n",
      ", punct\n",
      "algorithms conj\n",
      "and cc\n",
      "systems conj\n",
      "to aux\n",
      "extract xcomp\n",
      "knowledge dobj\n",
      "and cc\n",
      "insights conj\n",
      "from prep\n",
      "structured amod\n",
      "and cc\n",
      "unstructured conj\n",
      "data pobj\n",
      ", punct\n",
      "and cc\n",
      "apply conj\n",
      "knowledge dobj\n",
      "and cc\n",
      "actionable amod\n",
      "insights conj\n",
      "from prep\n",
      "data pobj\n",
      "across prep\n",
      "a det\n",
      "broad amod\n",
      "range pobj\n",
      "of prep\n",
      "application compound\n",
      "domains pobj\n",
      ". punct\n"
     ]
    }
   ],
   "source": [
    "# spaCy determines the dependency tree for it's doc. Like POS, we can see the dependency tags of each token. \n",
    "for token in single_sentence:\n",
    "    print(token.text, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'direct object'"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"dobj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"aeb0e0136ed348e8af12c9c41eb7926b-0\" class=\"displacy\" width=\"7050\" height=\"924.5\" direction=\"ltr\" style=\"max-width: none; height: 924.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Data</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">science</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">is</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">an</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">inter-</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">disciplinary</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">field</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">that</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">uses</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">scientific</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADJ</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">methods,</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">processes,</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">algorithms</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">and</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">CCONJ</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">systems</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">to</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">PART</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">extract</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">VERB</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">knowledge</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">and</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">CCONJ</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">insights</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">from</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">ADP</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">structured</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">ADJ</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">and</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">CCONJ</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">unstructured</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">ADJ</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">data,</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">and</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">CCONJ</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">apply</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">VERB</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4775\">knowledge</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4775\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4950\">and</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4950\">CCONJ</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5125\">actionable</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5125\">ADJ</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5300\">insights</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5300\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5475\">from</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5475\">ADP</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5650\">data</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5650\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5825\">across</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5825\">ADP</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6000\">a</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6000\">DET</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6175\">broad</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6175\">ADJ</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6350\">range</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6350\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6525\">of</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6525\">ADP</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6700\">application</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6700\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"834.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6875\">domains.</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6875\">NOUN</tspan>\n</text>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-0\" stroke-width=\"2px\" d=\"M70,789.5 C70,702.0 185.0,702.0 185.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M70,791.5 L62,779.5 78,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-1\" stroke-width=\"2px\" d=\"M245,789.5 C245,702.0 360.0,702.0 360.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M245,791.5 L237,779.5 253,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-2\" stroke-width=\"2px\" d=\"M595,789.5 C595,527.0 1070.0,527.0 1070.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M595,791.5 L587,779.5 603,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-3\" stroke-width=\"2px\" d=\"M770,789.5 C770,702.0 885.0,702.0 885.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M770,791.5 L762,779.5 778,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-4\" stroke-width=\"2px\" d=\"M945,789.5 C945,702.0 1060.0,702.0 1060.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M945,791.5 L937,779.5 953,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-5\" stroke-width=\"2px\" d=\"M420,789.5 C420,439.5 1075.0,439.5 1075.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1075.0,791.5 L1083.0,779.5 1067.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-6\" stroke-width=\"2px\" d=\"M1295,789.5 C1295,702.0 1410.0,702.0 1410.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1295,791.5 L1287,779.5 1303,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-7\" stroke-width=\"2px\" d=\"M1120,789.5 C1120,614.5 1415.0,614.5 1415.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1415.0,791.5 L1423.0,779.5 1407.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-8\" stroke-width=\"2px\" d=\"M1645,789.5 C1645,702.0 1760.0,702.0 1760.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1645,791.5 L1637,779.5 1653,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-9\" stroke-width=\"2px\" d=\"M1470,789.5 C1470,614.5 1765.0,614.5 1765.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1765.0,791.5 L1773.0,779.5 1757.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-10\" stroke-width=\"2px\" d=\"M1820,789.5 C1820,702.0 1935.0,702.0 1935.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1935.0,791.5 L1943.0,779.5 1927.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-11\" stroke-width=\"2px\" d=\"M1995,789.5 C1995,702.0 2110.0,702.0 2110.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M2110.0,791.5 L2118.0,779.5 2102.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-12\" stroke-width=\"2px\" d=\"M2170,789.5 C2170,702.0 2285.0,702.0 2285.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M2285.0,791.5 L2293.0,779.5 2277.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-13\" stroke-width=\"2px\" d=\"M2170,789.5 C2170,614.5 2465.0,614.5 2465.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M2465.0,791.5 L2473.0,779.5 2457.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-14\" stroke-width=\"2px\" d=\"M2695,789.5 C2695,702.0 2810.0,702.0 2810.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M2695,791.5 L2687,779.5 2703,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-15\" stroke-width=\"2px\" d=\"M1470,789.5 C1470,177.0 2840.0,177.0 2840.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M2840.0,791.5 L2848.0,779.5 2832.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-16\" stroke-width=\"2px\" d=\"M2870,789.5 C2870,702.0 2985.0,702.0 2985.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M2985.0,791.5 L2993.0,779.5 2977.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-17\" stroke-width=\"2px\" d=\"M3045,789.5 C3045,702.0 3160.0,702.0 3160.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M3160.0,791.5 L3168.0,779.5 3152.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-18\" stroke-width=\"2px\" d=\"M3045,789.5 C3045,614.5 3340.0,614.5 3340.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M3340.0,791.5 L3348.0,779.5 3332.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-19\" stroke-width=\"2px\" d=\"M3045,789.5 C3045,527.0 3520.0,527.0 3520.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M3520.0,791.5 L3528.0,779.5 3512.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-20\" stroke-width=\"2px\" d=\"M3745,789.5 C3745,527.0 4220.0,527.0 4220.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M3745,791.5 L3737,779.5 3753,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-21\" stroke-width=\"2px\" d=\"M3745,789.5 C3745,702.0 3860.0,702.0 3860.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M3860.0,791.5 L3868.0,779.5 3852.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-22\" stroke-width=\"2px\" d=\"M3745,789.5 C3745,614.5 4040.0,614.5 4040.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M4040.0,791.5 L4048.0,779.5 4032.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-23\" stroke-width=\"2px\" d=\"M3570,789.5 C3570,439.5 4225.0,439.5 4225.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M4225.0,791.5 L4233.0,779.5 4217.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-24\" stroke-width=\"2px\" d=\"M420,789.5 C420,89.5 4420.0,89.5 4420.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M4420.0,791.5 L4428.0,779.5 4412.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-25\" stroke-width=\"2px\" d=\"M420,789.5 C420,2.0 4600.0,2.0 4600.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M4600.0,791.5 L4608.0,779.5 4592.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-26\" stroke-width=\"2px\" d=\"M4620,789.5 C4620,702.0 4735.0,702.0 4735.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M4735.0,791.5 L4743.0,779.5 4727.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-27\" stroke-width=\"2px\" d=\"M4795,789.5 C4795,702.0 4910.0,702.0 4910.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M4910.0,791.5 L4918.0,779.5 4902.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-28\" stroke-width=\"2px\" d=\"M5145,789.5 C5145,702.0 5260.0,702.0 5260.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M5145,791.5 L5137,779.5 5153,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-29\" stroke-width=\"2px\" d=\"M4795,789.5 C4795,527.0 5270.0,527.0 5270.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-29\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M5270.0,791.5 L5278.0,779.5 5262.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-30\" stroke-width=\"2px\" d=\"M4620,789.5 C4620,352.0 5455.0,352.0 5455.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-30\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M5455.0,791.5 L5463.0,779.5 5447.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-31\" stroke-width=\"2px\" d=\"M5495,789.5 C5495,702.0 5610.0,702.0 5610.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-31\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M5610.0,791.5 L5618.0,779.5 5602.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-32\" stroke-width=\"2px\" d=\"M4620,789.5 C4620,264.5 5810.0,264.5 5810.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-32\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M5810.0,791.5 L5818.0,779.5 5802.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-33\" stroke-width=\"2px\" d=\"M6020,789.5 C6020,614.5 6315.0,614.5 6315.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-33\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M6020,791.5 L6012,779.5 6028,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-34\" stroke-width=\"2px\" d=\"M6195,789.5 C6195,702.0 6310.0,702.0 6310.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-34\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M6195,791.5 L6187,779.5 6203,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-35\" stroke-width=\"2px\" d=\"M5845,789.5 C5845,527.0 6320.0,527.0 6320.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-35\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M6320.0,791.5 L6328.0,779.5 6312.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-36\" stroke-width=\"2px\" d=\"M6370,789.5 C6370,702.0 6485.0,702.0 6485.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-36\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M6485.0,791.5 L6493.0,779.5 6477.0,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-37\" stroke-width=\"2px\" d=\"M6720,789.5 C6720,702.0 6835.0,702.0 6835.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-37\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M6720,791.5 L6712,779.5 6728,779.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-38\" stroke-width=\"2px\" d=\"M6545,789.5 C6545,614.5 6840.0,614.5 6840.0,789.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-aeb0e0136ed348e8af12c9c41eb7926b-0-38\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M6840.0,791.5 L6848.0,779.5 6832.0,779.5\" fill=\"currentColor\"/>\n</g>\n</svg></span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(single_sentence, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entity recognition\n",
    "\n",
    "[List of entity types in this spaCy model](https://spacy.io/models/en#en_core_web_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turing PERSON\n",
      "Jim Gray PERSON\n",
      "fourth ORDINAL\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity\n",
    "\n",
    "Add or modify a sentence in the original `sample_text` so that spaCy will detect a GPE. Then, in the cell below, write code to return a list of all entities that are either PERSON or GPE.\n",
    "\n",
    "**hint**: make sure to reprocess the `sample_text` with the `nlp` model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Turing\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n award winner \n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Jim Gray\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n imagined data science as a &quot;\n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    fourth\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n</mark>\n paradigm&quot; of science (empirical, theoretical, computational and now data-driven) and asserted that &quot;everything about science is changing because of the impact of information technology&quot; and the data deluge.</div></span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "single_sentence = list(doc.sents)[-1]\n",
    "displacy.render(single_sentence, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word, sentence, and document vectors\n",
    "\n",
    "SpaCy's medium (`md`) and large (`lg`) models include GloVe word vectors trained on the [Common Crawl](https://commoncrawl.org/). \n",
    "\n",
    "You could train your own vectors with `gensim` and `word2vec`, use a large language model, or many other libraries and algorithms. But, if you're text is fairly recent and especially from the web, the common crawl vectors might be enough, especially for exploratory work. \n",
    "\n",
    "`Token`s have vectors. `Doc`s and `Span`s have vectors that are the average of their token vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.7969e-01 -2.5516e-01 -2.1751e-01  1.8151e-01 -4.0652e-01  8.5208e-01\n",
      "  7.4484e-02  1.3682e-02  8.7480e-02  1.5056e+00 -5.3100e-01  2.8123e-02\n",
      "  5.7363e-02  9.2619e-02 -5.2687e-01  1.6689e-01 -1.9017e-01  3.1937e+00\n",
      " -2.1972e-01 -3.8853e-01  1.6916e-01  2.6669e-01 -3.5948e-01 -1.4874e-01\n",
      "  2.9541e-01  3.8212e-01  1.5826e-01 -9.2368e-02  3.4473e-01  1.0793e-01\n",
      " -2.2861e-01 -2.2966e-01  9.0178e-01 -4.6848e-02 -3.6522e-01 -2.9999e-02\n",
      " -3.2167e-01 -1.1985e-01 -3.0740e-01 -3.1308e-01 -1.8787e-01  4.7730e-01\n",
      " -1.3486e-01  2.3576e-01 -5.4592e-01 -2.6415e-02  1.2399e-01  1.2621e-01\n",
      "  2.8233e-01 -1.4344e-01 -1.3727e-01 -3.3906e-01 -1.0746e-01 -2.6406e-02\n",
      " -1.5055e-01  8.4884e-02 -3.0304e-01 -1.7760e-01  8.0063e-02 -5.1963e-01\n",
      "  4.8408e-01  7.4119e-01 -1.0525e-01  4.5329e-01  2.1668e-01  3.2206e-01\n",
      " -2.8967e-02  4.1205e-01  5.1266e-01  3.4068e-01  1.5061e-01  6.6381e-01\n",
      "  9.0662e-01 -3.7938e-01 -1.4235e-01  8.8749e-02  2.2335e-01 -4.2028e-01\n",
      "  1.4483e-02  2.1708e-01  2.1882e-01  2.3531e-01  4.5853e-01  4.5439e-02\n",
      "  1.5211e-01 -6.6370e-02 -5.1476e-01 -2.4227e-01  1.4526e-01  3.3054e-01\n",
      " -4.3838e-01 -1.6985e-01 -4.6600e-01 -2.0476e-01  6.6384e-02 -3.6122e-01\n",
      " -5.1252e-01  5.2345e-01  3.2872e-01 -2.0672e-01 -2.0748e-01  3.3687e-02\n",
      "  1.1464e-01  5.6206e-01 -5.4426e-01 -1.8048e+00  7.7697e-02 -2.2029e-01\n",
      "  5.4583e-01  3.0539e-01  8.6370e-02 -6.6535e-02  2.8269e-01  6.4179e-02\n",
      "  3.0537e-01  6.5276e-01 -1.8421e-01  3.7387e-01 -1.4403e-01  9.3120e-02\n",
      " -5.0647e-02  2.0830e-02 -2.7152e-01  3.3428e-01  5.5502e-02  8.0098e-02\n",
      "  3.2527e-01 -5.9392e-01 -5.9905e-02 -1.5223e-01  2.5757e-02  7.2118e-01\n",
      "  2.3447e-01 -8.0598e-02  2.9747e-01  3.4474e-02 -2.0550e-01 -8.8966e-02\n",
      "  2.2679e-01  3.0186e-02  5.3271e-01  1.9741e-02  3.6323e-01 -4.3930e-01\n",
      " -2.4581e-02 -1.1918e-01 -2.9403e-01 -2.7087e-01 -2.4977e-02 -7.8225e-02\n",
      " -3.6938e-02 -2.0189e-01  3.4638e-01  1.1567e-01 -9.2806e-02  2.4282e-03\n",
      " -1.8940e-01  7.9512e-01  1.0215e-01 -4.5610e-01  2.6313e-01  3.5474e-01\n",
      "  3.9645e-01 -3.4698e-01 -1.1092e+00  3.4560e-01 -2.2741e-02  3.8413e-01\n",
      "  1.7248e-01  3.3153e-02 -4.5580e-02 -3.0162e-01 -5.0915e-01  6.9286e-02\n",
      "  1.2332e-01  5.8060e-01  4.2208e-01 -3.1265e-01 -5.6140e-01  5.1744e-01\n",
      " -1.4081e-01 -4.4795e-01 -9.2364e-02  2.4048e-01  1.2188e-01  1.7213e-01\n",
      " -3.8169e-01  4.7736e-02 -1.7600e-02 -4.5049e-01  7.0348e-02 -4.1067e-01\n",
      " -5.8153e-02  6.5794e-01 -2.8645e-01 -1.1061e-01 -2.3676e-01 -9.1519e-02\n",
      " -4.5786e-01  4.3769e-02 -4.3425e-03 -9.7647e-01  5.7700e-01  3.2170e-01\n",
      " -6.9238e-02  3.2137e-02  2.0993e-01  6.1978e-01  3.0473e-03  6.6801e-02\n",
      " -1.2552e-01 -9.6190e-01 -5.9866e-01 -4.5744e-01 -2.5166e-01 -4.7375e-01\n",
      " -3.4200e-01  1.9530e-01 -4.0455e-01  3.2328e-02  2.2746e-01  7.3642e-01\n",
      " -1.6253e-02  5.9830e-02 -3.1066e-02  3.6150e-01  2.3273e-01 -1.4775e-01\n",
      "  2.5601e-01 -2.2402e-01 -3.3489e-02 -1.3261e-01  2.0764e-01 -3.7541e-02\n",
      " -3.8997e-01  5.9346e-01 -4.7838e-01 -3.9390e-01 -8.0494e-02 -2.9441e-01\n",
      "  8.8045e-03 -4.8581e-02  6.3625e-02 -2.2137e-01 -2.0573e-01 -8.8514e-01\n",
      "  4.2501e-01 -1.3249e-01  2.2507e-01  4.3022e-01  4.3783e-01 -1.2186e-01\n",
      " -2.0356e-01 -2.5380e-01  1.0491e-01 -1.9191e-01  1.6636e-01 -3.7805e-01\n",
      " -8.7550e-02 -3.9370e-01  1.4550e-01  4.6402e-01 -1.7460e-01 -3.4354e-01\n",
      " -3.2261e-01 -3.0236e-01  1.3846e-01  3.1979e-01  1.3566e+00 -3.8159e-01\n",
      " -4.0190e-01  5.1417e-02  5.0175e-01 -4.4934e-01  6.5471e-01  1.2148e-03\n",
      "  9.8401e-02  2.4437e-01 -4.4169e-01 -1.1503e-01  1.1916e-01  1.3663e-01\n",
      "  1.4279e-01  6.6230e-02  5.0051e-02 -1.7963e-01  1.8818e-02 -2.1234e-01\n",
      "  1.0654e-01 -4.2832e-01 -5.6139e-01  6.1635e-01  1.2405e-01  2.9348e-01\n",
      "  2.6429e-01 -4.8513e-01 -6.0542e-01  2.2297e-01 -5.7508e-01  5.5672e-02]\n",
      "[-3.6030e-01  3.6893e-02  2.1941e-01 -9.9548e-02 -7.4640e-02  3.9272e-01\n",
      " -7.1837e-01  2.4464e-01 -8.8964e-02  2.4763e+00 -5.4853e-01 -5.2036e-02\n",
      "  1.4768e-01  4.9527e-01 -1.7954e-01  2.0575e-01  2.4663e-01  1.4013e+00\n",
      " -4.8001e-01 -3.8316e-01  5.2198e-01 -1.2928e-01  6.2019e-02  1.5480e-01\n",
      "  5.6934e-01 -3.0260e-01  1.0634e-01  2.6798e-01 -5.1659e-03  3.4128e-01\n",
      " -5.2146e-01  2.4627e-01  4.2073e-01 -1.3535e-02  7.3479e-01 -3.9933e-02\n",
      " -1.1757e-02  4.0327e-01 -1.4134e-01  1.9437e-01  3.9649e-01 -1.3376e-01\n",
      " -4.0484e-01  3.2088e-01  2.5180e-01  7.6694e-02  9.4249e-02 -1.1245e-01\n",
      " -2.1022e-01 -5.0867e-01  4.4607e-01 -7.5964e-03  2.9939e-01 -2.5602e-01\n",
      " -5.0274e-01 -4.1465e-01  2.2768e-01 -4.1404e-01 -1.6366e-01 -1.3608e-01\n",
      " -1.3307e-01 -5.3627e-02  6.2552e-01 -7.3778e-02  4.8966e-01 -2.4253e-01\n",
      " -3.8385e-01 -2.0156e-01  4.3211e-02  1.6572e-02 -2.1803e-01 -6.1490e-01\n",
      " -1.3150e-01 -2.4474e-01 -2.5167e-02  6.5707e-01 -9.5978e-02  4.5935e-01\n",
      "  1.1010e-01  8.2390e-01 -5.2218e-01 -6.8328e-01  2.5383e-01  3.8977e-01\n",
      "  2.5374e-01 -9.2286e-01 -1.2830e+00 -1.0855e-01 -5.2049e-01  1.3286e-01\n",
      " -2.5398e-01  5.1866e-02 -4.9461e-01 -1.6515e-01 -2.2692e-01 -3.6744e-01\n",
      "  1.4451e-01  3.5044e-01 -2.6213e-02 -1.7611e-01  4.7645e-02 -1.5554e-01\n",
      "  1.7882e-01  1.6802e-01  6.8002e-02 -1.5011e+00 -1.9661e-01  8.1641e-02\n",
      " -6.4759e-02 -5.4262e-02  1.1862e-01  1.7008e-01 -9.4114e-02 -1.0587e+00\n",
      "  2.8446e-02  5.3940e-01 -4.2058e-01 -1.1745e-01  3.4082e-01 -2.3250e-01\n",
      "  5.3523e-01 -1.4242e-01  1.8311e-01  2.5294e-01  3.7254e-01  6.8514e-01\n",
      "  1.9549e-01  3.6213e-01  6.3849e-01  8.7757e-02  1.9779e-01 -1.6197e-01\n",
      "  4.5851e-02 -5.2041e-01  5.2955e-02 -1.4642e-01 -1.4673e-01 -9.5170e-03\n",
      "  3.5062e-01  5.0627e-02 -6.8578e-01 -1.1213e-01  3.4631e-01  3.8368e-01\n",
      "  2.8359e-01 -3.1045e-01 -2.3938e-01 -4.0919e-01 -6.2944e-01 -9.5835e-02\n",
      "  4.4405e-01 -4.3962e-01  7.8801e-02  4.2571e-01  2.0976e-01  6.5733e-02\n",
      " -1.5277e-01 -9.0189e-01  3.1689e-01  3.3731e-01  9.0652e-01 -5.9745e-01\n",
      "  2.6792e-01  7.0480e-02 -3.1768e-01  1.0780e-01 -2.5492e-01 -5.6920e-01\n",
      "  1.6735e-01  9.7226e-02  7.3922e-02 -1.1768e-01  1.7289e-01 -4.9097e-01\n",
      "  2.0582e-01 -1.7098e-02  1.3766e-01  8.0877e-02 -1.4878e-02 -4.8219e-01\n",
      "  1.8154e-01  3.1158e-01  4.9131e-01  4.7461e-02  2.0959e-01 -1.7905e-01\n",
      " -4.4750e-02  1.3173e-01  3.8842e-01 -1.9604e-02 -3.1393e-01 -3.6506e-01\n",
      " -6.5681e-01  4.6491e-02 -4.1720e-01  2.7897e-01  1.3164e-01 -1.7303e-01\n",
      "  7.4630e-01  9.1398e-02 -5.2191e-01  2.4694e-03  1.5099e-01  5.4087e-01\n",
      " -1.5279e-01  4.7377e-02  1.0102e-02  2.5490e-01  4.5261e-01 -5.5536e-04\n",
      " -4.9474e-01 -1.4781e-02  2.9270e-01 -1.1192e+00 -5.0434e-01 -4.1196e-01\n",
      " -2.7408e-01  3.0210e-01 -2.8968e-01 -1.8409e-01 -2.7783e-01 -1.6132e-01\n",
      " -3.4228e-01 -5.6827e-01  7.8474e-01  2.1584e-01 -1.7312e-01 -1.7983e-01\n",
      "  3.8934e-01  3.8110e-01 -2.4654e-01  2.3866e-01 -3.5739e-01 -4.9134e-01\n",
      " -3.7996e-01  8.0180e-02 -5.1150e-01  2.7952e-01 -9.5099e-02  2.1199e-01\n",
      " -1.5794e-01 -7.4861e-01 -6.4536e-01 -1.3789e-01  5.2847e-02  1.4087e-01\n",
      " -7.0385e-01 -1.5790e-01 -2.1180e-01  1.0944e-02  3.0777e-01  6.0693e-02\n",
      " -1.5124e-01 -3.4807e-01  7.3388e-01 -4.1446e-01 -3.1412e-01  4.4759e-02\n",
      "  1.3446e-01 -3.3184e-01  2.6226e-01  3.5356e-01 -3.0004e-01  2.8373e-01\n",
      "  5.6391e-01 -5.1395e-01 -3.3578e-01  2.7544e-02  6.5633e-01 -2.6583e-02\n",
      " -1.0377e+00  1.3228e-01  1.5099e-02  5.6454e-02  8.6147e-03  5.4601e-03\n",
      " -1.3493e-01 -2.4708e-01 -4.5862e-01 -4.9510e-02 -1.5387e-01 -3.7809e-01\n",
      " -2.2860e-01  4.2497e-02 -2.6729e-01 -3.3294e-01  2.4910e-01 -2.3316e-01\n",
      " -5.9566e-01  1.0306e-02  2.9487e-01  7.4849e-02  9.2992e-02  8.8193e-02\n",
      "  1.2973e-01 -1.8639e-01  1.4099e-01  1.6527e-01 -2.4393e-01 -8.7180e-02]\n",
      "[-8.4961e-02  5.0200e-01  2.3823e-03 -1.6755e-01  3.0721e-01 -2.3762e-01\n",
      "  1.6069e-01 -3.6786e-01 -5.8347e-02  2.4990e+00 -2.3647e-03  1.0732e-02\n",
      " -3.0422e-01  8.4579e-02 -4.0299e-02 -4.1562e-01 -2.4494e-02  1.4691e+00\n",
      " -5.2932e-02 -7.4413e-02 -3.9244e-01 -3.2535e-01 -2.2333e-01  5.6823e-03\n",
      "  3.5675e-01  1.9445e-01  5.6762e-02 -4.5502e-02 -2.8105e-01 -5.8896e-02\n",
      " -9.8626e-02  9.2177e-02  3.3172e-01 -3.9967e-02 -1.1766e-01  4.8373e-02\n",
      " -6.2241e-02 -1.0413e-01  9.9263e-04 -4.8925e-01  3.4786e-01  3.2724e-01\n",
      "  1.3882e-01 -1.9917e-01  1.2995e-01  6.0549e-02 -2.3714e-01 -5.1295e-01\n",
      " -3.7396e-01  1.2902e-01  5.5797e-02  3.3444e-01 -1.8025e-01 -3.4740e-02\n",
      "  2.8323e-01 -9.5301e-02  2.1143e-01 -7.6149e-02  1.5069e-01 -1.7441e-01\n",
      " -7.4768e-03 -7.8287e-02 -1.2751e-01  2.2545e-01  3.5101e-02 -6.1015e-01\n",
      " -2.6812e-01  6.1632e-02 -3.0503e-01 -1.3405e-01 -4.4271e-01 -1.7720e-01\n",
      "  1.7663e-01 -3.1210e-01 -2.5722e-01 -2.4858e-02  7.2504e-02 -7.9759e-02\n",
      " -1.9214e-01  5.9602e-01  1.2880e-01 -7.4629e-02 -1.5812e-01  3.6394e-01\n",
      "  2.3055e-01 -4.2175e-01 -9.0651e-02 -3.0085e-01  1.7940e-01 -2.9786e-01\n",
      " -1.0642e-01  4.7239e-01 -1.3837e-01 -1.0161e-01  8.0134e-02  4.0715e-02\n",
      " -3.6976e-01 -3.7066e-02  1.0436e-01  1.7904e-01  1.5702e-01 -7.4670e-02\n",
      " -2.9431e-01  1.2829e-01  5.5211e-02 -4.3906e-01 -6.8231e-02  9.7107e-02\n",
      " -2.8209e-01 -8.6528e-02 -2.4204e-01  2.8734e-02 -2.1509e-01  2.7152e-02\n",
      " -1.7996e-01  1.9317e-01 -2.7929e-01  2.9415e-01 -1.0965e-01 -1.0432e-01\n",
      " -5.2170e-01 -4.6789e-02  1.3743e-01 -1.5518e-01 -1.0359e-01  1.8853e-01\n",
      " -1.2684e-01 -6.7278e-01  3.4483e-02 -2.2937e-01 -9.8073e-02 -7.0157e-02\n",
      "  8.4374e-02  2.6594e-01  2.3104e-01 -2.9251e-01 -8.7209e-02 -2.3342e-01\n",
      "  6.3759e-02 -1.3556e-01 -8.4046e-01  2.4681e-01  3.0498e-01  3.5438e-01\n",
      "  1.4137e-01 -3.6720e-01  2.3321e-01 -1.5497e-01  4.8364e-01  1.4711e-02\n",
      " -2.4176e-01  3.7589e-02  1.9829e-01 -6.9403e-02 -1.7362e-03  4.1694e-02\n",
      " -3.4193e-01 -2.0034e-01 -4.5581e-01 -1.2504e-01  1.3954e-01  3.2275e-02\n",
      " -5.2130e-03  4.5422e-02 -2.6574e-03 -2.6266e-01  6.4168e-02 -1.4231e-01\n",
      "  3.5709e-04 -2.3253e-01  2.7615e-02 -7.4282e-02  1.8671e-01 -1.2994e-01\n",
      " -4.3731e-01  1.4550e-01  4.4838e-02 -1.9022e-01 -1.5401e-01  1.4188e-01\n",
      "  9.8269e-02 -4.2930e-02 -2.7478e-01 -3.3224e-01 -3.2167e-01 -1.0509e-01\n",
      " -1.9816e-01 -6.5097e-02 -9.1251e-02  1.9528e-01 -3.3297e-01 -1.5504e-01\n",
      " -4.7688e-01  3.1985e-01  1.9886e-01  1.1501e-01  5.5757e-02 -5.4307e-02\n",
      "  2.8851e-01  2.7982e-01  1.3960e-02 -1.2891e-03 -2.3128e-01  7.5396e-02\n",
      "  4.3587e-02 -1.3937e-01 -6.2935e-02  1.2568e-01  9.5235e-02 -8.5203e-02\n",
      " -2.4241e-01 -4.8771e-02  9.5937e-02 -2.2347e-01  2.3503e-01  3.1517e-01\n",
      " -1.4900e-02  2.1739e-01 -1.9431e-01 -2.3255e-01 -2.2961e-01  4.8297e-02\n",
      "  1.6050e-01 -1.6100e-02  4.2770e-02 -3.2367e-01  1.4680e-01  2.4551e-01\n",
      "  7.5506e-02 -3.9703e-02 -1.0321e-01  1.6194e-01  2.7132e-01  4.6348e-02\n",
      " -9.2743e-02 -1.4929e-01  2.7378e-01 -3.6958e-01 -4.1530e-01  1.8402e-01\n",
      " -4.9775e-02  6.9670e-02  1.3447e-01  1.7788e-01 -4.7586e-02 -3.6491e-01\n",
      " -1.3733e-01 -4.8119e-01  2.4681e-01 -8.9842e-02  3.7939e-02 -1.8284e-01\n",
      "  4.7012e-01 -9.9584e-02 -1.8365e-01 -7.1821e-02  4.1607e-01 -1.8581e-01\n",
      "  1.8400e-01 -2.9028e-02  4.1228e-01  2.2856e-02  5.0915e-02 -1.1911e-01\n",
      "  8.1231e-02  1.3845e-01  4.6595e-02 -4.3974e-02  6.3601e-01  3.7101e-03\n",
      "  9.3937e-02 -9.3442e-02 -4.7606e-01 -2.6427e-01 -2.3044e-02 -5.8241e-02\n",
      "  1.1440e-01 -5.1702e-02  3.5225e-01  2.5341e-01  5.7256e-01  2.2867e-01\n",
      "  8.5401e-03 -6.2531e-02 -3.2118e-02 -1.5647e-01 -8.4344e-02  7.6667e-02\n",
      "  3.4515e-01 -1.9452e-01  8.7003e-02 -7.8201e-02 -6.9673e-02 -1.6993e-01\n",
      "  2.3598e-01  2.7550e-01 -6.7180e-02 -2.1511e-01 -2.6304e-01 -6.0173e-03]\n",
      "[-1.1662e-02  1.9483e-01  8.8854e-02  5.4694e-01  2.5764e-01  1.5619e-01\n",
      " -3.4131e-01 -2.1666e-01 -1.4187e-01  2.4525e+00 -6.4806e-02  8.5481e-02\n",
      " -1.1925e-01  8.7107e-03  1.8261e-01 -2.9207e-01 -1.1578e-01  1.5710e+00\n",
      " -3.1973e-01 -4.1279e-01 -1.8129e-01 -2.9101e-01 -2.1584e-01  1.9685e-01\n",
      "  1.5240e-01 -9.0306e-02 -9.7694e-02  9.8791e-02  6.7369e-02 -2.4964e-01\n",
      "  9.9773e-02  3.2079e-01 -5.6697e-02  3.2238e-01  1.5905e-01 -4.5345e-01\n",
      "  1.1294e-01 -5.0674e-01  2.3202e-01 -5.5625e-01  3.9208e-01  1.4811e-01\n",
      " -1.8637e-01 -6.2775e-01 -2.9390e-02 -1.0555e-01 -9.5531e-02 -9.7434e-02\n",
      "  1.9720e-01  2.2059e-01 -1.1017e-01 -4.8332e-02 -4.8414e-02  2.9998e-03\n",
      "  9.9272e-02 -2.3553e-02  1.4603e-02 -9.8494e-02 -1.4167e-01  1.1831e-01\n",
      " -1.2322e-02  3.6239e-02  1.0297e-01  1.1158e-01 -4.1930e-02 -1.6625e-01\n",
      "  2.8472e-01 -2.2051e-01 -4.9708e-02  3.2561e-01 -2.4400e-01 -2.8140e-02\n",
      " -7.1356e-03 -2.2616e-01 -8.9478e-02  8.2447e-02  4.8198e-02 -2.8326e-01\n",
      " -7.4620e-01  6.0872e-01  2.1592e-01  1.3517e-01 -5.8790e-03  1.5697e-01\n",
      "  1.7543e-02 -6.5070e-01 -6.0810e-01  1.3962e-01  2.8628e-01 -3.4076e-01\n",
      " -3.2782e-01  3.3876e-01  2.2207e-01 -1.4818e-01 -3.2918e-01 -1.5938e-01\n",
      " -3.8448e-01 -1.2595e-01 -9.9549e-02 -2.8544e-01  9.3137e-03  7.8235e-03\n",
      " -9.3138e-02 -6.8065e-02  2.6759e-02 -1.0398e+00  2.4762e-01  3.8398e-01\n",
      "  6.6230e-01 -2.6994e-01  1.9174e-01 -1.3892e-01 -3.7396e-01 -1.6413e-04\n",
      " -9.4473e-02  9.7790e-02 -4.4733e-01  1.7914e-01 -2.2492e-01  1.1517e-02\n",
      " -2.1837e-01 -2.7095e-02  2.2307e-01 -3.4854e-01 -1.8707e-01  3.0603e-03\n",
      " -4.2032e-01 -1.8487e-01 -5.6208e-01 -1.5139e-01 -1.0828e-01 -2.1532e-01\n",
      " -2.7416e-01 -2.0356e-01  2.4666e-01 -2.3746e-01 -1.2539e-01 -1.4658e-02\n",
      "  4.4677e-02 -6.8932e-01 -7.1280e-01  1.9282e-01  4.3114e-02  9.2519e-02\n",
      " -7.1066e-02 -3.7312e-01  2.5582e-01 -2.9538e-01  3.4666e-01 -2.0368e-01\n",
      "  1.8214e-01  3.2011e-01  1.0774e-01 -1.9064e-01  4.9321e-01  1.1759e-01\n",
      " -7.7502e-02 -2.0347e-01 -3.0257e-01 -2.4968e-01 -3.3035e-01 -1.1076e-01\n",
      "  1.7257e-01 -2.5248e-01 -1.5597e-01 -9.5579e-02  2.9602e-01 -1.1353e-01\n",
      "  1.1378e-01  4.2170e-02 -1.0416e-01  1.0275e-01  3.2486e-01  1.2846e-01\n",
      "  8.6711e-03 -8.7829e-02  4.1325e-02 -2.5309e-01 -4.4164e-01 -1.3862e-01\n",
      " -3.1100e-01  1.5086e-01 -2.9916e-01 -5.4871e-01 -4.6731e-01 -1.8136e-01\n",
      " -1.3318e-01  2.4436e-01  1.3889e-02 -2.1335e-01 -3.1292e-01  2.0530e-01\n",
      " -6.1686e-01  5.6070e-01  2.2628e-01  4.2597e-01 -3.0931e-01 -1.9921e-01\n",
      " -1.6589e-01  1.6017e-01  5.9949e-02  1.6039e-01 -9.4529e-02  2.1313e-01\n",
      "  4.3970e-01 -1.1975e-01  2.0910e-01  2.0094e-01  1.7543e-01  1.8910e-01\n",
      " -4.4454e-01  7.7866e-02  8.1136e-02 -3.6833e-01 -4.0159e-01  6.2475e-01\n",
      " -5.4086e-02  5.2973e-01  4.8823e-02 -3.1570e-02 -1.2963e-02  5.5686e-02\n",
      " -9.4021e-02  7.0565e-02 -3.7699e-01 -3.6916e-01  6.4286e-02  4.1971e-01\n",
      "  1.0837e-01 -1.3602e-01 -5.6549e-02 -4.0015e-02  3.4090e-01  1.1575e-01\n",
      " -5.4581e-02 -2.0758e-01  4.0873e-01  1.2970e-03 -3.6174e-01  5.9374e-01\n",
      "  7.4668e-02  2.7985e-01  3.3846e-01  5.1372e-01  4.8615e-01 -2.6198e-01\n",
      "  2.5109e-01  2.3477e-01  1.6903e-01 -1.4265e-01 -1.9448e-01 -1.0927e-01\n",
      "  2.1903e-01  1.3169e-01 -7.3529e-02  5.8470e-02  3.0656e-01 -2.1659e-01\n",
      " -3.5887e-02  2.3820e-01 -1.9286e-01  2.3738e-01  3.2946e-01 -4.3599e-01\n",
      "  1.6886e-01 -2.1193e-01 -6.9089e-02 -4.8063e-01  4.0617e-01 -5.1688e-03\n",
      "  6.8038e-01 -1.8951e-02 -2.3077e-01 -3.9166e-03 -3.6334e-01  3.2451e-01\n",
      " -3.7190e-01 -6.5041e-02  5.0366e-01  1.8549e-01  4.2846e-01  3.3319e-01\n",
      "  1.4532e-01  2.3860e-02 -7.0744e-02 -6.6983e-01 -1.1862e-01  7.2780e-02\n",
      "  2.7465e-01 -4.9775e-02  2.1254e-03  1.8468e-01 -2.1512e-03 -2.5295e-01\n",
      " -3.4570e-01 -2.7130e-01  1.2307e-01 -5.4666e-02 -1.9340e-01  1.3995e-01]\n",
      "[-1.9647e-01 -3.3882e-01 -2.6649e-01 -9.4845e-02  2.6098e-01  1.9540e-01\n",
      "  5.0244e-01  6.8390e-02 -5.0714e-01  7.6053e-01 -2.3476e-01 -1.2539e-01\n",
      "  1.9481e-01 -1.7388e-01  5.1756e-02  1.5885e-01 -2.5564e-01  1.1288e+00\n",
      "  3.1160e-01  2.1397e-02  3.6868e-02 -3.9818e-02  4.2908e-01  9.6841e-02\n",
      "  7.4924e-01 -1.4132e-03 -3.6238e-01 -1.4627e-01 -2.9358e-01  5.8828e-01\n",
      "  2.2822e-01  2.6931e-01  5.1276e-01 -1.4142e-01 -1.0341e-01 -2.4158e-01\n",
      "  7.2871e-02 -2.1823e-01 -4.8648e-01 -2.2978e-01 -1.2788e-01 -4.1255e-01\n",
      "  9.1891e-02  2.8975e-01 -1.1025e-01 -1.1998e-01  1.8513e-01  1.5312e-01\n",
      " -4.5709e-01  3.4080e-01  5.0376e-01  3.6813e-01 -8.8471e-02 -1.6909e-01\n",
      " -1.5869e-01 -9.8765e-02 -6.0040e-02  8.7318e-02  1.4048e-01  6.6614e-02\n",
      " -1.8816e-02  7.8033e-01  1.7666e-01 -5.4235e-01 -2.9566e-01  1.9100e-01\n",
      "  5.3290e-01  3.9846e-01 -3.4338e-01 -5.0964e-02 -1.1582e-01  3.6917e-01\n",
      " -1.0958e-01 -3.4682e-01 -1.1737e-01 -2.6896e-01 -8.9812e-01  1.7786e-01\n",
      "  3.9609e-01 -4.4409e-01  3.0145e-01  1.1399e-01 -2.5381e-01  1.7784e-01\n",
      " -5.5387e-01 -5.0760e-02  1.2824e-01  5.3990e-02  5.6473e-01  1.4778e-01\n",
      " -3.4142e-01 -1.0848e-01 -3.0109e-03 -2.2037e-01  1.0202e-02  1.3302e-01\n",
      "  2.9940e-01 -9.4141e-02 -5.0524e-02  3.6450e-01 -2.6455e-01  1.1275e-01\n",
      " -2.0829e-02  1.2527e-01 -2.6829e-01 -2.0170e+00 -4.5418e-01  3.8828e-02\n",
      "  2.8267e-01  3.0156e-02  9.6267e-02  2.0225e-01 -6.1680e-01 -3.7427e-01\n",
      "  1.4722e-01 -1.8052e-01 -1.7572e-01 -1.3640e-01 -3.6301e-02  1.3754e-02\n",
      "  2.0687e-01  6.2168e-03 -2.8012e-01  1.2333e-01 -3.5692e-01  5.1363e-01\n",
      "  2.4344e-01  2.5545e-01 -2.6024e-01  1.2844e-01  3.3041e-01 -4.0090e-01\n",
      " -2.2334e-01 -7.3695e-01  3.0819e-01  2.1144e-01 -3.0911e-02 -4.3976e-01\n",
      " -2.7660e-02 -1.2589e-01 -1.6411e-01 -5.7969e-01 -6.6972e-02  3.7165e-01\n",
      "  9.9592e-02 -1.7833e-02 -2.9258e-01 -2.2405e-01 -4.3166e-01  2.0504e-02\n",
      "  1.1339e-01  2.9960e-01  5.1439e-02 -5.4996e-01  7.0577e-01 -1.8466e-01\n",
      " -4.3610e-01  2.3786e-01 -4.5223e-02  1.6508e-01 -6.3076e-02  8.6580e-02\n",
      "  1.9183e-01 -2.5237e-01 -3.9398e-01  9.9479e-02  4.0962e-02  2.9221e-01\n",
      " -5.0950e-01  7.3038e-01 -2.0877e-01  2.8530e-01  2.0371e-01 -1.8555e-01\n",
      "  4.7168e-01 -2.9760e-01 -5.7694e-01  4.5405e-01 -2.8407e-02  1.5397e-01\n",
      " -8.4665e-02 -6.8802e-02 -3.5147e-01  3.6139e-01 -6.2373e-02  2.1918e-01\n",
      " -3.0664e-01  3.0258e-01  5.8829e-01  8.4228e-02  5.6029e-02  2.7820e-02\n",
      " -1.6248e-01  3.5627e-01 -4.7908e-02  6.7979e-02  5.5536e-01 -2.5994e-01\n",
      " -1.9776e-01  5.0524e-01  4.9104e-01  6.8618e-02  3.4517e-01  7.5162e-01\n",
      " -2.1250e-01 -5.7358e-01 -1.9556e-01  1.7928e-01 -4.3639e-01 -5.5558e-02\n",
      "  3.9887e-01  5.8220e-01 -3.6412e-02  3.3493e-01 -3.4779e-01  5.7461e-02\n",
      " -4.2974e-03  9.4797e-02 -9.6886e-02  5.6104e-01 -4.7439e-01 -3.2005e-01\n",
      " -1.0035e-02 -1.8523e-01 -1.9101e-01  2.7606e-01  2.1674e-02  6.9173e-02\n",
      "  4.3725e-01 -5.9741e-01 -1.9515e-01 -1.0957e-01 -8.0983e-01  8.7643e-03\n",
      " -5.5376e-02 -2.9051e-01 -9.4368e-02 -8.1207e-02 -2.5421e-01  3.6317e-02\n",
      "  5.6391e-01  2.5966e-01 -5.9923e-02 -5.0266e-02  3.1817e-01 -1.8975e-02\n",
      "  2.6559e-01  4.9507e-01 -2.7861e-01 -2.9907e-01  3.3599e-01 -2.3055e-02\n",
      " -2.2538e-01  9.7451e-03  2.7757e-02  4.2272e-01 -7.1324e-01 -4.9409e-01\n",
      " -1.4304e-01 -3.1582e-01  5.2664e-01  4.7792e-02 -5.8202e-02  3.7888e-02\n",
      " -1.2010e-01 -1.5898e-01  2.4652e-01  2.6407e-02 -1.5729e-01  1.6239e-01\n",
      " -1.4868e-01  2.3189e-01 -3.4626e-01  6.3945e-01  1.2584e-01  2.4115e-01\n",
      " -1.8857e-01 -4.0307e-01 -5.0013e-01  1.7129e-01  3.1607e-01 -1.6318e-01\n",
      " -1.2029e-01 -3.2113e-01 -2.2432e-01 -2.1233e-01  6.3830e-02 -1.4915e-02\n",
      "  6.1737e-03 -8.2142e-03  9.5057e-02 -1.0268e-01 -1.5678e-01 -4.9648e-01\n",
      " -4.8692e-02 -2.2168e-02  3.4582e-01 -2.5471e-01  1.8719e-01  2.9896e-01]\n"
     ]
    }
   ],
   "source": [
    "# token vectors\n",
    "for token in doc[:5]:\n",
    "    print(token.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([-1.12466343e-01,  1.59790739e-01, -1.12997115e-01, -4.50736731e-02,\n        2.63751261e-02,  1.57385424e-01, -2.99619976e-02,  3.67342643e-02,\n       -3.36680375e-02,  1.97251296e+00, -2.44648248e-01,  9.13238153e-02,\n        7.33316541e-02,  1.35665610e-02, -1.04197107e-01,  9.55005549e-03,\n       -3.44923213e-02,  1.45000446e+00, -2.52511472e-01, -1.59972414e-01,\n        7.37948045e-02, -1.34542231e-02, -1.16475768e-01, -2.10609008e-02,\n        1.27918169e-01,  4.55922149e-02,  9.04883593e-02,  7.26802796e-02,\n        5.18373325e-02, -3.09815146e-02, -6.85465857e-02,  6.20514154e-02,\n        1.03448085e-01,  1.80202927e-02,  9.48346183e-02, -1.20624557e-01,\n       -4.04222123e-02,  2.51795407e-02, -9.20449644e-02, -7.20806345e-02,\n        5.79685532e-03,  2.01701690e-02, -5.31277433e-02,  3.71526629e-02,\n       -4.70825359e-02,  7.30216131e-03, -8.69988874e-02,  7.25259911e-03,\n        3.56209576e-02, -4.34230939e-02,  3.70069854e-02,  6.34394810e-02,\n       -8.38835612e-02,  1.39412023e-02, -5.94236813e-02,  5.04453033e-02,\n        4.38129343e-03, -4.60065976e-02, -1.77737224e-04, -5.89732155e-02,\n        5.09192795e-02,  1.32135406e-01,  7.41065443e-02,  1.04579188e-01,\n        1.36124045e-01, -5.31062186e-02, -1.38433846e-02,  6.28597215e-02,\n        5.95446862e-02,  9.23867822e-02, -2.25944277e-02,  2.10813023e-02,\n        2.08163321e-01, -7.46560469e-02, -6.30279165e-03,  2.15213336e-02,\n        2.72566173e-02, -4.45702747e-02,  2.57694982e-02,  2.39788130e-01,\n       -5.38651310e-02, -1.12283546e-02,  4.02752236e-02, -3.87607738e-02,\n        8.59616473e-02, -3.22796553e-01, -3.32738131e-01,  2.36026645e-02,\n        1.40156940e-01,  1.36769652e-01, -1.24242358e-01, -4.45568264e-02,\n       -1.19151421e-01, -7.96418544e-03,  7.80140013e-02, -8.98324177e-02,\n       -8.86285678e-02,  8.48328546e-02, -2.30157096e-02, -1.13485910e-01,\n        1.35617955e-02, -1.18417181e-02, -7.66356438e-02,  6.19939677e-02,\n        5.94757171e-03, -9.74524438e-01, -3.05077918e-02, -1.03355886e-03,\n        1.32134303e-01,  8.02700296e-02,  1.68494955e-02, -3.12585160e-02,\n        5.17264977e-02, -1.91017628e-01, -2.02555433e-02,  7.64088482e-02,\n       -8.23606644e-03,  2.12080572e-02,  4.84660715e-02, -5.29553799e-04,\n        7.36732632e-02, -2.32148226e-02, -4.30085063e-02,  1.04073524e-01,\n       -5.31580672e-03,  1.41605377e-01,  4.03601713e-02,  4.72563086e-03,\n        8.61080438e-02, -3.57838571e-02,  8.00019875e-02,  6.04974851e-02,\n       -1.87674891e-02, -5.67350276e-02,  1.61597375e-02,  9.52640995e-02,\n       -3.65440808e-02, -4.74623777e-02,  9.18169841e-02,  1.02009304e-01,\n       -4.89619344e-01,  2.61687282e-02,  1.29348412e-01,  1.86323412e-02,\n       -1.31208068e-02, -7.70404637e-02,  1.14291273e-02, -6.65658191e-02,\n        2.00646021e-03, -2.76918262e-02,  8.20310935e-02, -7.97823593e-02,\n        1.02983922e-01,  7.10898638e-02, -5.43739498e-02,  7.10362345e-02,\n       -7.76080862e-02, -5.56526743e-02, -1.12491529e-02, -3.18233445e-02,\n        8.75494480e-02,  2.44938061e-02,  9.11289360e-03, -5.45119345e-02,\n       -2.25340068e-01, -7.68765435e-02,  5.31299263e-02, -4.97767404e-02,\n        1.37496576e-01,  3.44428048e-02,  4.56633903e-02, -4.43606591e-03,\n        1.02622388e-02, -9.87063721e-02, -2.38134917e-02,  7.87752569e-02,\n        6.52627572e-02, -3.37645449e-02,  6.66469056e-03, -1.08695045e-01,\n        1.30888466e-02, -1.88931748e-02,  1.55876332e-03, -1.71726570e-02,\n       -3.74169275e-02,  7.09774578e-03, -1.14039950e-01,  5.11427596e-02,\n        1.97436847e-02, -6.30818754e-02, -6.17874078e-02, -9.50611755e-02,\n       -8.63229334e-02,  1.72048569e-01, -6.33594841e-02,  1.21831276e-01,\n       -2.88422611e-02, -8.62381086e-02, -6.17090054e-02,  1.97839990e-01,\n       -1.19926430e-01, -2.30861321e-01, -1.70418918e-02,  1.39852703e-01,\n        4.45105843e-02, -7.23554865e-02,  7.52194151e-02,  8.55809227e-02,\n        4.48288061e-02, -1.17300579e-03, -1.90561563e-01, -1.30466178e-01,\n       -5.93962744e-02, -1.91265717e-01, -2.67124213e-02, -3.68939377e-02,\n       -9.91971418e-02,  1.17812626e-01, -2.38702387e-01, -1.30588459e-02,\n        3.09016220e-02,  1.32901728e-01, -2.92205270e-02, -1.07358880e-02,\n        4.87047695e-02,  4.18190323e-02,  2.69748848e-02,  1.81566831e-02,\n        1.31973013e-01,  8.47052261e-02, -1.31529227e-01,  1.82611775e-02,\n        3.19063663e-02,  3.50069045e-03, -1.48142666e-01,  3.76665555e-02,\n       -1.46690622e-01, -8.74848217e-02, -5.79462685e-02,  4.71340865e-02,\n        4.96870875e-02, -6.62029237e-02, -5.95793612e-02, -4.82477397e-02,\n        1.25932142e-01, -1.88853785e-01, -1.17098540e-01, -1.50205866e-01,\n       -1.20502055e-01,  8.67333487e-02,  1.68184221e-01, -1.46788852e-02,\n       -8.70941952e-02, -7.58395642e-02,  8.33540335e-02,  1.74587145e-02,\n        6.04539700e-02, -1.24757059e-01, -4.36422713e-02,  1.35080833e-02,\n        1.02809355e-01,  1.31343186e-01, -2.02403925e-02,  1.08733140e-01,\n        4.59184460e-02, -1.58250421e-01, -7.43955746e-02,  1.73621327e-02,\n        6.02723122e-01, -8.25070366e-02, -2.06372783e-01, -3.64806391e-02,\n       -1.83648500e-03, -1.83833137e-01, -1.62772704e-02, -3.11493333e-02,\n        5.39531261e-02,  8.85941535e-02, -9.07665342e-02,  1.06739573e-01,\n        1.56156465e-01,  4.43367520e-03,  8.01719129e-02, -1.29077926e-01,\n       -7.60276616e-02, -1.69583231e-01,  5.95827550e-02, -1.12000063e-01,\n        8.79838914e-02, -1.57161891e-01, -2.17746168e-01,  9.64793488e-02,\n        3.85547280e-02,  8.73342380e-02,  2.23764554e-02, -8.43601972e-02,\n       -3.48785743e-02,  1.30708460e-02, -6.74109459e-02,  6.68289587e-02],\n      dtype=float32)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doc vector\n",
    "doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([-1.41003445e-01,  1.21739812e-01, -1.44238576e-01, -1.61007531e-02,\n       -7.10073160e-03,  2.14003816e-01, -1.12373112e-02,  6.85715303e-02,\n        5.83196618e-03,  1.91060233e+00, -2.13344872e-01,  1.18561260e-01,\n        1.79695562e-02, -1.80001184e-02, -6.21123314e-02,  2.77977157e-02,\n       -3.61825936e-02,  1.64743721e+00, -2.42472798e-01, -1.71403274e-01,\n        8.64852220e-02,  2.87005603e-02, -1.58356890e-01, -5.06506860e-02,\n        1.23856753e-01,  8.57934132e-02,  1.38494328e-01,  6.12009577e-02,\n        5.48274778e-02, -7.91425779e-02, -6.47969842e-02,  8.37085396e-02,\n        1.58478186e-01, -3.10242288e-02,  2.82637123e-02, -1.50990441e-01,\n       -1.29540525e-02, -1.76589098e-02, -6.41159415e-02, -1.09551206e-01,\n        6.33410551e-03,  2.59006233e-03, -3.98420878e-02,  4.04196084e-02,\n       -6.28071949e-02,  4.23986278e-02, -8.43424052e-02,  3.92410383e-02,\n        1.95257366e-02, -1.95598211e-02,  8.04203600e-02,  2.54307482e-02,\n       -8.72328877e-02,  5.58819175e-02, -4.52078655e-02,  3.83148491e-02,\n       -1.69727542e-02,  8.29672441e-03, -3.09048127e-02, -4.43894230e-02,\n        9.58940610e-02,  2.16052458e-01,  4.82544415e-02,  7.55001083e-02,\n        1.84258863e-01, -3.73471156e-02,  1.44948876e-02,  1.23211868e-01,\n        7.91679099e-02,  6.85829967e-02, -8.31002146e-02,  6.19109794e-02,\n        2.30751589e-01, -6.11231923e-02, -2.25567073e-02, -3.90198007e-02,\n        8.23384151e-02, -3.86225954e-02, -4.22362909e-02,  1.85229719e-01,\n       -1.39397532e-02, -8.62641784e-04,  1.20567558e-02, -3.62682976e-02,\n        8.43828097e-02, -3.18290383e-01, -3.78674090e-01,  1.71502277e-01,\n        2.14556456e-01,  1.24022692e-01, -8.86812136e-02, -5.88922352e-02,\n       -3.33057716e-02,  4.74356115e-02,  1.23895444e-01, -3.97729091e-02,\n       -5.02477661e-02,  5.33203706e-02, -7.65579343e-02, -1.54082075e-01,\n        7.29965717e-02, -2.59499792e-02, -8.65790024e-02,  6.36607558e-02,\n       -4.02769772e-03, -1.25020695e+00, -3.57181542e-02, -1.97201893e-02,\n        1.59783781e-01,  5.11451773e-02,  6.70719668e-02, -1.10003151e-01,\n        7.31539056e-02, -1.47544622e-01, -8.63042325e-02,  1.00963987e-01,\n        6.66788891e-02,  5.05149215e-02,  4.24134135e-02,  6.22999519e-02,\n        1.26861960e-01, -4.43215817e-02, -8.49415362e-02,  8.19795430e-02,\n       -1.73659306e-02,  1.41168013e-01, -1.36889098e-02,  2.91627571e-02,\n        2.68160589e-02, -7.53486007e-02,  1.11009628e-01,  6.49791285e-02,\n       -3.66824381e-02, -2.12227199e-02, -6.45128544e-04,  7.03770667e-02,\n       -2.91665997e-02, -9.97815952e-02,  7.28263035e-02,  1.51597530e-01,\n       -2.40498096e-01, -4.19378933e-03,  1.37699619e-01, -2.06306912e-02,\n       -5.46673201e-02, -1.21629432e-01,  8.89004581e-03, -1.05134867e-01,\n        3.76341753e-02, -4.09183875e-02,  1.23338021e-01, -6.47197291e-02,\n        9.01392847e-02,  6.20479695e-02, -7.47167766e-02,  5.89231662e-02,\n       -7.37615749e-02, -1.03099132e-02, -3.59843634e-02, -8.65074098e-02,\n        8.45212489e-02,  3.34168179e-03,  1.36777973e-02, -1.40419547e-02,\n       -1.75719678e-01, -7.78849572e-02,  5.97858019e-02, -8.59286711e-02,\n        1.10481635e-01,  5.14285415e-02,  8.42331126e-02, -7.48944795e-03,\n        3.53788361e-02, -1.17909782e-01, -1.86648034e-02,  4.26201597e-02,\n       -9.08095826e-05, -7.77593441e-03,  5.70187606e-02, -7.36685321e-02,\n        1.48240859e-02, -4.28897562e-03,  4.37928922e-03,  1.30607234e-02,\n       -4.14821617e-02, -4.36608829e-02, -1.25095963e-01,  2.63141394e-02,\n        2.92520635e-02, -1.96116660e-02, -7.48984143e-02, -6.18622191e-02,\n       -6.07647672e-02,  2.29079410e-01, -6.39166087e-02,  1.50312334e-01,\n       -2.25822069e-02, -7.78106451e-02, -4.96527366e-02,  1.71915814e-01,\n       -1.09834865e-01, -2.97959447e-01,  5.63341239e-03,  2.00507522e-01,\n        4.62727398e-02, -6.74498156e-02,  5.72094545e-02,  1.11402966e-01,\n       -6.15632115e-03, -4.21981588e-02, -2.14539990e-01, -1.06940620e-01,\n       -1.29643425e-01, -1.61781624e-01, -3.53384838e-02, -3.58863436e-02,\n       -7.07592741e-02,  6.90225810e-02, -2.22155064e-01, -1.19531888e-03,\n        3.03124879e-02,  1.32578894e-01, -1.86086781e-02,  5.75456247e-02,\n        5.75621706e-03,  7.34173134e-02,  2.82575134e-02,  1.31652914e-02,\n        1.41302854e-01,  1.21847704e-01, -1.63795173e-01, -1.92738287e-02,\n       -2.45417114e-02,  1.02113575e-01, -1.15684919e-01,  1.02421632e-02,\n       -1.50101647e-01, -1.07878156e-01, -5.13536409e-02,  3.12827304e-02,\n        7.76705965e-02, -5.25007360e-02, -6.87968060e-02, -5.76508567e-02,\n        1.54776916e-01, -2.26384223e-01, -1.36855230e-01, -1.41429633e-01,\n       -1.39803395e-01,  1.50480688e-01,  1.72177732e-01, -1.56631861e-02,\n       -1.45290896e-01, -1.93974897e-02,  9.23773348e-02, -2.70122420e-02,\n        9.82296914e-02, -1.76485166e-01, -6.76584691e-02,  1.44068589e-02,\n        2.76434813e-02,  7.52507299e-02,  9.62797832e-03,  8.51009861e-02,\n        1.98342428e-02, -1.46677077e-01, -8.17012936e-02,  1.94295160e-02,\n        6.87211394e-01, -7.97512084e-02, -1.87391788e-01,  1.79408044e-02,\n        2.01946422e-02, -1.61986038e-01, -9.14706662e-02, -3.33649223e-03,\n        6.93431124e-02,  8.03978592e-02, -5.06753437e-02,  1.51014343e-01,\n        1.69203386e-01,  4.72050197e-02,  1.03911377e-01, -1.23335183e-01,\n       -5.51988110e-02, -1.84392035e-01,  9.07609910e-02, -8.52230638e-02,\n        1.20329425e-01, -2.13633403e-01, -2.29768038e-01,  7.74517283e-02,\n       -2.13549212e-02,  8.96795392e-02, -4.26927283e-02, -9.30136964e-02,\n        6.18686154e-02, -9.77913104e-03, -4.63698506e-02,  8.04625228e-02],\n      dtype=float32)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence/span vector\n",
    "list(doc.sents)[0].vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fine, but for exploratory work, we might just be interested in some similarity measures between tokens, sentences, or documents. SpaCy uses the common cosine similarity measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Data 1.0\n",
      "Data science 0.2967368\n",
      "Data is 0.28532642\n",
      "Data an 0.2718177\n",
      "Data inter 0.19982958\n",
      "Data - 0.031793762\n",
      "Data disciplinary 0.18646398\n",
      "Data field 0.40077925\n",
      "Data that 0.38139\n",
      "Data uses 0.40483338\n",
      "science Data 0.2967368\n",
      "science science 1.0\n",
      "science is 0.30085263\n",
      "science an 0.2522719\n",
      "science inter 0.19687814\n",
      "science - 0.065442264\n",
      "science disciplinary 0.47277686\n",
      "science field 0.45549664\n",
      "science that 0.3774315\n",
      "science uses 0.31416386\n",
      "is Data 0.28532642\n",
      "is science 0.30085263\n",
      "is is 1.0\n",
      "is an 0.63675654\n",
      "is inter 0.094093345\n",
      "is - 0.17651182\n",
      "is disciplinary 0.29116082\n",
      "is field 0.33907786\n",
      "is that 0.6942723\n",
      "is uses 0.4684848\n",
      "an Data 0.2718177\n",
      "an science 0.2522719\n",
      "an is 0.63675654\n",
      "an an 1.0\n",
      "an inter 0.1947275\n",
      "an - 0.07939471\n",
      "an disciplinary 0.22468801\n",
      "an field 0.37208116\n",
      "an that 0.57462156\n",
      "an uses 0.38908035\n",
      "inter Data 0.19982958\n",
      "inter science 0.19687814\n",
      "inter is 0.094093345\n",
      "inter an 0.1947275\n",
      "inter inter 1.0\n",
      "inter - 0.0022585576\n",
      "inter disciplinary 0.21024904\n",
      "inter field 0.16123219\n",
      "inter that 0.17105532\n",
      "inter uses 0.0850028\n",
      "- Data 0.031793762\n",
      "- science 0.065442264\n",
      "- is 0.17651182\n",
      "- an 0.07939471\n",
      "- inter 0.0022585576\n",
      "- - 1.0\n",
      "- disciplinary 0.09172175\n",
      "- field 0.058502074\n",
      "- that 0.07875418\n",
      "- uses 0.023306878\n",
      "disciplinary Data 0.18646398\n",
      "disciplinary science 0.47277686\n",
      "disciplinary is 0.29116082\n",
      "disciplinary an 0.22468801\n",
      "disciplinary inter 0.21024904\n",
      "disciplinary - 0.09172175\n",
      "disciplinary disciplinary 1.0\n",
      "disciplinary field 0.37707162\n",
      "disciplinary that 0.34631708\n",
      "disciplinary uses 0.19265743\n",
      "field Data 0.40077925\n",
      "field science 0.45549664\n",
      "field is 0.33907786\n",
      "field an 0.37208116\n",
      "field inter 0.16123219\n",
      "field - 0.058502074\n",
      "field disciplinary 0.37707162\n",
      "field field 1.0\n",
      "field that 0.3775761\n",
      "field uses 0.28150606\n",
      "that Data 0.38139\n",
      "that science 0.3774315\n",
      "that is 0.6942723\n",
      "that an 0.57462156\n",
      "that inter 0.17105532\n",
      "that - 0.07875418\n",
      "that disciplinary 0.34631708\n",
      "that field 0.3775761\n",
      "that that 1.0\n",
      "that uses 0.48728704\n",
      "uses Data 0.40483338\n",
      "uses science 0.31416386\n",
      "uses is 0.4684848\n",
      "uses an 0.38908035\n",
      "uses inter 0.0850028\n",
      "uses - 0.023306878\n",
      "uses disciplinary 0.19265743\n",
      "uses field 0.28150606\n",
      "uses that 0.48728704\n",
      "uses uses 1.0\n"
     ]
    }
   ],
   "source": [
    "for token1 in doc[:10]:\n",
    "    for token2 in doc[:10]:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Looking at the results, can you explain the scale of the similarity score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. \n",
      " Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. \n",
      " 1.0\n",
      "----------------------------------------------\n",
      "Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. \n",
      " Data science is related to data mining, machine learning and big data.\n",
      "\n",
      " \n",
      " 0.92242813\n",
      "----------------------------------------------\n",
      "Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. \n",
      " Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyze actual phenomena\" with data. \n",
      " 0.9411189\n",
      "----------------------------------------------\n",
      "Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. \n",
      " It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. \n",
      " 0.9420639\n",
      "----------------------------------------------\n",
      "Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. \n",
      " Turing award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge. \n",
      " 0.9107233\n",
      "----------------------------------------------\n",
      "Data science is related to data mining, machine learning and big data.\n",
      "\n",
      " \n",
      " Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. \n",
      " 0.92242813\n",
      "----------------------------------------------\n",
      "Data science is related to data mining, machine learning and big data.\n",
      "\n",
      " \n",
      " Data science is related to data mining, machine learning and big data.\n",
      "\n",
      " \n",
      " 1.0\n",
      "----------------------------------------------\n",
      "Data science is related to data mining, machine learning and big data.\n",
      "\n",
      " \n",
      " Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyze actual phenomena\" with data. \n",
      " 0.92573965\n",
      "----------------------------------------------\n",
      "Data science is related to data mining, machine learning and big data.\n",
      "\n",
      " \n",
      " It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. \n",
      " 0.90154475\n",
      "----------------------------------------------\n",
      "Data science is related to data mining, machine learning and big data.\n",
      "\n",
      " \n",
      " Turing award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge. \n",
      " 0.8975779\n",
      "----------------------------------------------\n",
      "Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyze actual phenomena\" with data. \n",
      " Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. \n",
      " 0.9411189\n",
      "----------------------------------------------\n",
      "Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyze actual phenomena\" with data. \n",
      " Data science is related to data mining, machine learning and big data.\n",
      "\n",
      " \n",
      " 0.92573965\n",
      "----------------------------------------------\n",
      "Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyze actual phenomena\" with data. \n",
      " Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyze actual phenomena\" with data. \n",
      " 1.0\n",
      "----------------------------------------------\n",
      "Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyze actual phenomena\" with data. \n",
      " It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. \n",
      " 0.9316018\n",
      "----------------------------------------------\n",
      "Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyze actual phenomena\" with data. \n",
      " Turing award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge. \n",
      " 0.9511204\n",
      "----------------------------------------------\n",
      "It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. \n",
      " Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. \n",
      " 0.9420639\n",
      "----------------------------------------------\n",
      "It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. \n",
      " Data science is related to data mining, machine learning and big data.\n",
      "\n",
      " \n",
      " 0.90154475\n",
      "----------------------------------------------\n",
      "It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. \n",
      " Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyze actual phenomena\" with data. \n",
      " 0.9316018\n",
      "----------------------------------------------\n",
      "It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. \n",
      " It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. \n",
      " 1.0\n",
      "----------------------------------------------\n",
      "It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. \n",
      " Turing award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge. \n",
      " 0.93096936\n",
      "----------------------------------------------\n",
      "Turing award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge. \n",
      " Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. \n",
      " 0.9107233\n",
      "----------------------------------------------\n",
      "Turing award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge. \n",
      " Data science is related to data mining, machine learning and big data.\n",
      "\n",
      " \n",
      " 0.8975779\n",
      "----------------------------------------------\n",
      "Turing award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge. \n",
      " Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyze actual phenomena\" with data. \n",
      " 0.9511204\n",
      "----------------------------------------------\n",
      "Turing award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge. \n",
      " It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. \n",
      " 0.93096936\n",
      "----------------------------------------------\n",
      "Turing award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge. \n",
      " Turing award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge. \n",
      " 1.0\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sent1 in doc.sents:\n",
    "    for sent2 in doc.sents:\n",
    "        print(sent1.text, \"\\n\", sent2.text, \"\\n\", sent1.similarity(sent2))\n",
    "        print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule based matcher\n",
    "\n",
    "Rule-based matching is an incredibly powerful complement to the statistic models of spaCy. It's also a bit complex though, and it's worth looking at the docs [here](https://spacy.io/usage/rule-based-matching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains.\n",
      "Data science is related to data mining, machine learning and big data.\n",
      "\n",
      "\n",
      "Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyze actual phenomena\" with data.\n",
      "It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.\n",
      "Turing award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Available token attributes for the `Matcher` pattern](https://spacy.io/usage/rule-based-matching#adding-patterns-attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll define a pattern as a list of dictionaries, where each dictionary describes a token\n",
    "pattern = [{'LOWER': 'data'},\n",
    "           {'POS': 'NOUN'}]\n",
    "# The Matcher expects a list of patterns\n",
    "matcher.add(\"data+noun\", [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12112088598235855885 data+noun 0 2 Data science\n",
      "12112088598235855885 data+noun 45 47 Data science\n",
      "12112088598235855885 data+noun 50 52 data mining\n",
      "12112088598235855885 data+noun 60 62 Data science\n",
      "12112088598235855885 data+noun 70 72 data analysis\n",
      "12112088598235855885 data+noun 126 128 data science\n",
      "12112088598235855885 data+noun 167 169 data deluge\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = doc[start:end]\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the easiest ways to build up these `Matcher` patterns is to use Explosion's online [Rule-based Matcher Explorer](https://explosion.ai/demos/matcher). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with multiple documents (a corpus)\n",
    "\n",
    "For a small corpus, you can build a list or dictionary of processed spaCy docs. Once you have that list or dictionary, approach it in terms of using the type of code we've written above, but applied over the larger data structure. \n",
    "\n",
    "For larger corpora, though, you might need to think about streaming data or distributed processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this if in Colab\n",
    "# Don't run this if in Binder\n",
    "!wget https://github.com/csbailey5t/ODSC_text_analysis/blob/master/archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if in Colab\n",
    "# normally we would just use `unzip`, but Colab seems to be having issues with zip files and utilities, so 7-zip it is. \n",
    "!7z x archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if in Binder\n",
    "!unzip archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "228"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fns = glob.glob(\"sotu/*.txt\")\n",
    "len(fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for fn in fns:\n",
    "    with open(fn, 'r') as f:\n",
    "        texts.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.52 s, sys: 744 ms, total: 6.26 s\n",
      "Wall time: 6.53 s\n"
     ]
    }
   ],
   "source": [
    "%time corpus = [nlp(text) for text in texts[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker PERSON\n",
      "Congress ORG\n",
      "Today marks MONEY\n",
      "first ORDINAL\n",
      "Washington GPE\n",
      "1790 DATE\n",
      "the\n",
      "Nation ORG\n",
      "American NORP\n",
      "George\n",
      " PERSON\n",
      "Washington GPE\n",
      "Winston Churchill PERSON\n",
      "Franklin Delano Roosevelt PERSON\n",
      "a day DATE\n",
      "Douglas MacArthur\n",
      " PERSON\n",
      "Dwight Eisenhower PERSON\n",
      "John F. Kennedy PERSON\n",
      "Chamber ORG\n",
      "last year DATE\n",
      "Washington GPE\n",
      "Congress ORG\n",
      "Washington GPE\n",
      "State ORG\n",
      "America GPE\n",
      "tonight TIME\n",
      "American NORP\n",
      "America GPE\n",
      "Detroit GPE\n",
      "Steubenville GPE\n",
      "Newark GPE\n",
      "Chicago GPE\n",
      "millions CARDINAL\n",
      "Americans NORP\n",
      "last\n",
      "year DATE\n",
      "The last decade DATE\n",
      "1970 DATE\n",
      "1974 DATE\n",
      "the spring of 1980 DATE\n",
      "the last 6 months of 1980 DATE\n",
      "annual DATE\n",
      "17 percent PERCENT\n",
      "21.5\n",
      "percent PERCENT\n",
      "8 million CARDINAL\n",
      "1981 DATE\n",
      "first ORDINAL\n",
      "3-year DATE\n",
      "15 3/4 percent PERCENT\n",
      "12.4\n",
      "percent PERCENT\n",
      "8.9 CARDINAL\n",
      "the month of December DATE\n",
      "5.2 percent PERCENT\n",
      "Americans NORP\n",
      "today DATE\n",
      "A year ago DATE\n",
      "Americans NORP\n",
      "Six CARDINAL\n",
      "10 CARDINAL\n",
      "Americans NORP\n",
      "about\n",
      " CARDINAL\n",
      "Congress ORG\n",
      "American NORP\n",
      "Congress ORG\n",
      "Congress ORG\n",
      "the beginning of this century DATE\n",
      "American NORP\n",
      "50 years DATE\n",
      "States GPE\n",
      "1981 DATE\n",
      "23,000 CARDINAL\n",
      "the Federal Register ORG\n",
      "1980 DATE\n",
      "just 6 months DATE\n",
      "$2 billion MONEY\n",
      "thousands CARDINAL\n",
      "Americans NORP\n",
      "America GPE\n",
      "last year DATE\n",
      "several\n",
      "decades DATE\n",
      "days DATE\n",
      "weeks DATE\n",
      "months DATE\n",
      "Americans NORP\n",
      "the months ahead DATE\n",
      "tonight TIME\n",
      "Union ORG\n",
      "two CARDINAL\n",
      "First ORDINAL\n",
      "decades DATE\n",
      "Second ORDINAL\n",
      "four CARDINAL\n",
      "the Federal Reserve System ORG\n",
      "trillion-dollar MONEY\n",
      "Congress ORG\n",
      "several years ahead DATE\n",
      "only one CARDINAL\n",
      "some $25 billion MONEY\n",
      "less than a hundred billion dollars MONEY\n",
      "three CARDINAL\n",
      "1976 DATE\n",
      "1980 DATE\n",
      "$54 billion MONEY\n",
      "1980 DATE\n",
      "one CARDINAL\n",
      "American NORP\n",
      "this year DATE\n",
      "American NORP\n",
      "America GPE\n",
      "Tonight TIME\n",
      "American NORP\n",
      "this year DATE\n",
      "last\n",
      "year DATE\n",
      "about $5 billion MONEY\n",
      "75,000 CARDINAL\n",
      "February 8th DATE\n",
      "the Departments of Energy and Education ORG\n",
      "two CARDINAL\n",
      "America GPE\n",
      "America GPE\n",
      "America GPE\n",
      "only 6 years ago DATE\n",
      "only one CARDINAL\n",
      "Today DATE\n",
      "three-quarters\n",
      " CARDINAL\n",
      "Congress ORG\n",
      "American NORP\n",
      "16,000 percent PERCENT\n",
      "the last 15 years DATE\n",
      "Medicare ORG\n",
      "Medicaid ORG\n",
      "11.2 billion MONEY\n",
      "almost 60 billion CARDINAL\n",
      "more than 5 CARDINAL\n",
      "just 10 years DATE\n",
      "1980 DATE\n",
      "one CARDINAL\n",
      "Medicare ORG\n",
      "Medicaid ORG\n",
      "One CARDINAL\n",
      "August DATE\n",
      "$44 billion MONEY\n",
      "the next 3 years DATE\n",
      "American NORP\n",
      "some $63 billion MONEY\n",
      "4 Years DATE\n",
      "Federal ORG\n",
      "Federal Government ORG\n",
      "95 million CARDINAL\n",
      "every day DATE\n",
      "one CARDINAL\n",
      "seven CARDINAL\n",
      "America GPE\n",
      "last\n",
      "year DATE\n",
      "More than one-half billion dollars CARDINAL\n",
      "the National Institute of Health ORG\n",
      "over $100 million MONEY\n",
      "Americans NORP\n",
      "the past few\n",
      "decades DATE\n",
      "1960 DATE\n",
      "the Federal Government ORG\n",
      "132 CARDINAL\n",
      "$7 billion MONEY\n",
      "approximately 500 CARDINAL\n",
      "36 CARDINAL\n",
      "66 CARDINAL\n",
      "90 CARDINAL\n",
      "Congress ORG\n",
      "at least 166 CARDINAL\n",
      "Congress ORG\n",
      "one CARDINAL\n",
      "Democratic NORP\n",
      "The National Government ORG\n",
      "Federal ORG\n",
      "one CARDINAL\n",
      "the Federal Government ORG\n",
      "un ORG\n",
      "some $47 billion MONEY\n",
      "State ORG\n",
      "nearly 10 years DATE\n",
      "Congress ORG\n",
      "State ORG\n",
      "fiscal 1984 DATE\n",
      "the Federal Government ORG\n",
      "Medicaid ORG\n",
      "Medicare ORG\n",
      "States GPE\n",
      "1984 DATE\n",
      "the Federal Government ORG\n",
      "50 CARDINAL\n",
      "$28 billion MONEY\n",
      "the next 4 years DATE\n",
      "two CARDINAL\n",
      "Federal ORG\n",
      "1988 DATE\n",
      "States GPE\n",
      "40 DATE\n",
      "States GPE\n",
      "State ORG\n",
      "1980 DATE\n",
      "the Federal Government ORG\n",
      "America GPE\n",
      "America GPE\n",
      "20 years ago DATE\n",
      "the Voting Rights\n",
      "Act LAW\n",
      "10-year DATE\n",
      "today DATE\n",
      "State ORG\n",
      "Americans NORP\n",
      "American NORP\n",
      "Three hundred and eighty-five thousand QUANTITY\n",
      "thousands CARDINAL\n",
      "Americans NORP\n",
      "America GPE\n",
      "Task Force ORG\n",
      "Fifty CARDINAL\n",
      "State ORG\n",
      "first ORDINAL\n",
      "one CARDINAL\n",
      "today DATE\n",
      "House ORG\n",
      "Senate ORG\n",
      "Union ORG\n",
      "tonight TIME\n",
      "the past year DATE\n",
      "the\n",
      "year ahead DATE\n",
      "Ottawa GPE\n",
      "Cancun GPE\n",
      "America GPE\n",
      "the Caribbean Basin LOC\n",
      "Caribbean LOC\n",
      "Cuba GPE\n",
      "Libya GPE\n",
      "America GPE\n",
      "America GPE\n",
      "Poland GPE\n",
      "Soviet NORP\n",
      "America GPE\n",
      "Poland GPE\n",
      "American NORP\n",
      "January 30th a day DATE\n",
      "Poland GPE\n",
      "the European Parliament ORG\n",
      "March 21st DATE\n",
      "Afghanistan GPE\n",
      "those days DATE\n",
      "Nation ORG\n",
      "last November 18th DATE\n",
      "the Soviet Union GPE\n",
      "Geneva GPE\n",
      "Soviets NORP\n",
      "the last decade DATE\n",
      "Soviet NORP\n",
      "Soviets NORP\n",
      "Europe LOC\n",
      "Asia LOC\n",
      "the Middle East\n",
      " LOC\n",
      "Soviet NORP\n",
      "the Foreign Assistance Act LAW\n",
      "America GPE\n",
      "Soviet NORP\n",
      "Winston Churchill PERSON\n",
      "Soviets NORP\n",
      "the year DATE\n",
      "Americans NORP\n",
      "200 years ago DATE\n",
      "Americans NORP\n",
      "tonight TIME\n",
      "Armed Forces ORG\n",
      "that night TIME\n",
      "first ORDINAL\n",
      "Clark Field FAC\n",
      "Philippines GPE\n",
      "Jeremiah Denton PERSON\n",
      "America GPE\n",
      "Just 2 weeks ago DATE\n",
      "Potomac GPE\n",
      "American NORP\n",
      "one CARDINAL\n",
      "Lenny Skutnik PERSON\n",
      "American NORP\n",
      "millions CARDINAL\n",
      "America GPE\n",
      "American NORP\n",
      "A hundred and twenty years ago QUANTITY\n",
      "Abraham Lincoln PERSON\n",
      "Congress ORG\n",
      "Congress ORG\n",
      "American NORP\n",
      "America GPE\n",
      "two\n",
      "centuries DATE\n",
      "Congress ORG\n",
      "this\n",
      "Chamber FAC\n",
      "their day DATE\n",
      "Earth LOC\n",
      "9 p.m. TIME\n",
      "the House Chamber ORG\n",
      "Capitol FAC\n",
      "Thomas P. O'Neill PERSON\n",
      "the House of\n",
      "Representatives ORG\n",
      "Senate ORG\n",
      "House of Representatives ORG\n",
      "two CARDINAL\n",
      "the last four years DATE\n",
      "the Civil War EVENT\n",
      "Ours ORG\n",
      "the twentieth century DATE\n",
      "the\n",
      "days DATE\n",
      "Washington GPE\n",
      "the days DATE\n",
      "Lincoln ORG\n",
      "over a century DATE\n",
      "Congress ORG\n",
      "first ORDINAL\n",
      "past year DATE\n",
      "State ORG\n",
      "some\n",
      " CARDINAL\n",
      "Congress ORG\n",
      "Congress ORG\n",
      "Constitution LAW\n",
      "Congress ORG\n",
      "Congress ORG\n",
      "Congressional ORG\n",
      "Congress ORG\n",
      "States GPE\n",
      "Congress ORG\n",
      "Constitution LAW\n",
      "Congress ORG\n",
      "the Department of Justice ORG\n",
      "Congress ORG\n",
      "One CARDINAL\n",
      "first ORDINAL\n",
      "American NORP\n",
      "American NORP\n",
      "One CARDINAL\n",
      "Congress ORG\n",
      "the\n",
      "Congress ORG\n",
      "seasons DATE\n",
      "a\n",
      "century DATE\n",
      "first ORDINAL\n",
      "Congress ORG\n",
      "House ORG\n",
      "Cabinet ORG\n",
      "Senate ORG\n",
      "Congress ORG\n",
      "Senate ORG\n",
      "Cuba GPE\n",
      "May 20 DATE\n",
      "the United States GPE\n",
      "Cuban NORP\n",
      "Cuba GPE\n",
      "first ORDINAL\n",
      "Cuba GPE\n",
      "Platt\n",
      " LAW\n",
      "Cuba GPE\n",
      "Cuba GPE\n",
      "Cuba GPE\n",
      "Cuban NORP\n",
      "the American Continent LOC\n",
      "Great Britain GPE\n",
      "Senate ORG\n",
      "the United States GPE\n",
      "Newfoundland GPE\n",
      "State ORG\n",
      "Blaine PERSON\n",
      "The last century DATE\n",
      "some\n",
      " CARDINAL\n",
      "The Hague GPE\n",
      "Mexico GPE\n",
      "first ORDINAL\n",
      "The Hague Court ORG\n",
      "last summer DATE\n",
      "first ORDINAL\n",
      "the United States GPE\n",
      "The Hague GPE\n",
      "Congress ORG\n",
      "Hawaiian NORP\n",
      "Congress ORG\n",
      "isthmian canal FAC\n",
      "Panama GPE\n",
      "the French Panama Canal\n",
      "Company ORG\n",
      "Colombia GPE\n",
      "the twentieth century DATE\n",
      "Administration ORG\n",
      "America GPE\n",
      "America GPE\n",
      "America GPE\n",
      "United GPE\n",
      "the fall of 1901 DATE\n",
      "State ORG\n",
      "California GPE\n",
      "Philippine NORP\n",
      "Hawaii GPE\n",
      "Congress ORG\n",
      "Congress ORG\n",
      "several years DATE\n",
      "Congress ORG\n",
      "first ORDINAL\n",
      "Congress ORG\n",
      "Congress ORG\n",
      "the Commercial Pacific Cable Company ORG\n",
      "the U. S. S. Nero ORG\n",
      "trans-Pacific LOC\n",
      "Congress ORG\n",
      "China GPE\n",
      "Grant PERSON\n",
      "first ORDINAL\n",
      "French NORP\n",
      "Congress ORG\n",
      "December, 1875 DATE\n",
      "second ORDINAL\n",
      "French NORP\n",
      "Brest ORG\n",
      "St. Pierre GPE\n",
      "Cape Cod LOC\n",
      "the Philippine Islands LOC\n",
      "China GPE\n",
      "British NORP\n",
      "Manila GPE\n",
      "Hongkong GPE\n",
      "all-American NORP\n",
      "Pacific LOC\n",
      "the Chinese Empire GPE\n",
      "Honolulu GPE\n",
      "the Philippine Islands GPE\n",
      "a few months DATE\n",
      "one CARDINAL\n",
      "Congress ORG\n",
      "Porto GPE\n",
      "Rico LAW\n",
      "July 4 last DATE\n",
      "one hundred and twenty-sixth CARDINAL\n",
      "the Philippine Islands LOC\n",
      "the Mohammedan Moros ORG\n",
      "Filipinos NORP\n",
      "Filipino LANGUAGE\n",
      "Orientals NORP\n",
      "Orientals NORP\n",
      "Japanese NORP\n",
      "Philippine NORP\n",
      "American NORP\n",
      "Philippines GPE\n",
      "Army ORG\n",
      "Philippines GPE\n",
      "only some fifteen thousand CARDINAL\n",
      "over one hundred thousand CARDINAL\n",
      "the Philippine Islands LOC\n",
      "Army ORG\n",
      "Philippine NORP\n",
      "Filipinos NORP\n",
      "Army ORG\n",
      "Army ORG\n",
      "last year DATE\n",
      "Army ORG\n",
      "West Point PRODUCT\n",
      "the National Guard ORG\n",
      "House ORG\n",
      "the National Guard ORG\n",
      "the United States GPE\n",
      "first ORDINAL\n",
      "the Admiral of the Navy ORG\n",
      "the\n",
      "Navy ORG\n",
      "Navy ORG\n",
      "Navy ORG\n",
      "every year DATE\n",
      "Army ORG\n",
      "first ORDINAL\n",
      "first ORDINAL\n",
      "isthmian canal ORG\n",
      "Navy ORG\n",
      "the\n",
      "Navy ORG\n",
      "The Monroe Doctrine LAW\n",
      "American NORP\n",
      "navy ORG\n",
      "navy ORG\n",
      "Navy ORG\n",
      "a thousand CARDINAL\n",
      "the Naval\n",
      "School FAC\n",
      "Annapolis GPE\n",
      "Annapolis GPE\n",
      "the Post-Office Department ORG\n",
      "the Post-Office Department ORG\n",
      "the fiscal year ending DATE\n",
      "June 30 DATE\n",
      "121,848,047.26 MONEY\n",
      "$10,216,853.87\n",
      " MONEY\n",
      "the preceding year DATE\n",
      "the year 1860\n",
      " DATE\n",
      "8,518,067 MONEY\n",
      "Congress ORG\n",
      "yearly DATE\n",
      "about two per cent MONEY\n",
      "yearly DATE\n",
      "ten per cent MONEY\n",
      "November 1, 1902 DATE\n",
      "11,650 CARDINAL\n",
      "about one-third CARDINAL\n",
      "the United States GPE\n",
      "Department ORG\n",
      "10,748 CARDINAL\n",
      "daily DATE\n",
      "Congress ORG\n",
      "Congress ORG\n",
      "recent years DATE\n",
      "the far West LOC\n",
      "States GPE\n",
      "West LOC\n",
      "One hundred\n",
      " CARDINAL\n",
      "sixty acres QUANTITY\n",
      "one hundred and sixty acres QUANTITY\n",
      "only one CARDINAL\n",
      "ten acres QUANTITY\n",
      "the\n",
      "Government ORG\n",
      "Congress ORG\n",
      "Congress ORG\n",
      "Congress ORG\n",
      "Alaska GPE\n",
      "Alaska GPE\n",
      "thirty-five years DATE\n",
      "Alaska GPE\n",
      "Alaska GPE\n",
      "Alaskan NORP\n",
      "the\n",
      "Commission of Fish and Fisheries ORG\n",
      "Alaska GPE\n",
      "Congress ORG\n",
      "Congressional ORG\n",
      "Alaska GPE\n",
      "Indians NORP\n",
      "the Indian Territory LOC\n",
      "Indian NORP\n",
      "Indians NORP\n",
      "Indian NORP\n",
      "Indian NORP\n",
      "Indians NORP\n",
      "first ORDINAL\n",
      "Indian NORP\n",
      "Indians NORP\n",
      "Indian NORP\n",
      "smith PERSON\n",
      "Indian NORP\n",
      "English LANGUAGE\n",
      "Indians NORP\n",
      "recent years DATE\n",
      "the\n",
      "Republic GPE\n",
      "annual DATE\n",
      "only ten inches QUANTITY\n",
      "Louisiana GPE\n",
      "Texas GPE\n",
      "the South-west LOC\n",
      "the\n",
      "North LOC\n",
      "East LOC\n",
      "Congress ORG\n",
      "the Smithsonian Institution ORG\n",
      "Museum ORG\n",
      "buffalo GPE\n",
      "The District of Columbia GPE\n",
      "National Government ORG\n",
      "Washington GPE\n",
      "Washington GPE\n",
      "the\n",
      "District LOC\n",
      "Congress ORG\n",
      "Washington GPE\n",
      "the District of Columbia GPE\n",
      "navy ORG\n",
      "District LOC\n",
      "1893 DATE\n",
      "August 1, 1901 DATE\n",
      "thousands CARDINAL\n",
      "the\n",
      " ORG\n",
      "Senate ORG\n",
      "Government ORG\n",
      "Departments ORG\n",
      "Congress ORG\n",
      "the year DATE\n",
      "Government ORG\n",
      "the District of Columbia GPE\n",
      "Congress ORG\n",
      "White\n",
      " ORG\n",
      "House ORG\n",
      "Washington GPE\n",
      "the University of Virginia ORG\n",
      "Jefferson GPE\n",
      "Mount Vernon GPE\n",
      "the\n",
      "Nation's ORG\n",
      "Executive Departments ORG\n",
      "Congress ORG\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus[:2]:\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "295"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect all geo-political entities from whole corpus\n",
    "gpes = [(ent.text, ent.label_) for ent in doc.ents for doc in corpus if ent.label_ == \"GPE\"]\n",
    "len(gpes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('Washington', 'GPE'),\n ('Washington', 'GPE'),\n ('Washington', 'GPE'),\n ('Washington', 'GPE'),\n ('Washington', 'GPE'),\n ('States', 'GPE'),\n ('States', 'GPE'),\n ('States', 'GPE'),\n ('States', 'GPE'),\n ('States', 'GPE'),\n ('Cuba', 'GPE'),\n ('Cuba', 'GPE'),\n ('Cuba', 'GPE'),\n ('Cuba', 'GPE'),\n ('Cuba', 'GPE'),\n ('the United States', 'GPE'),\n ('the United States', 'GPE'),\n ('the United States', 'GPE'),\n ('the United States', 'GPE'),\n ('the United States', 'GPE')]"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpes[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{('Alaska', 'GPE'),\n ('America', 'GPE'),\n ('Annapolis', 'GPE'),\n ('California', 'GPE'),\n ('China', 'GPE'),\n ('Colombia', 'GPE'),\n ('Cuba', 'GPE'),\n ('Great Britain', 'GPE'),\n ('Hawaii', 'GPE'),\n ('Hongkong', 'GPE'),\n ('Honolulu', 'GPE'),\n ('Jefferson', 'GPE'),\n ('Louisiana', 'GPE'),\n ('Manila', 'GPE'),\n ('Mexico', 'GPE'),\n ('Mount Vernon', 'GPE'),\n ('Newfoundland', 'GPE'),\n ('Panama', 'GPE'),\n ('Philippines', 'GPE'),\n ('Porto', 'GPE'),\n ('St. Pierre', 'GPE'),\n ('States', 'GPE'),\n ('Texas', 'GPE'),\n ('The District of Columbia', 'GPE'),\n ('The Hague', 'GPE'),\n ('United', 'GPE'),\n ('Washington', 'GPE'),\n ('buffalo', 'GPE'),\n ('the\\nRepublic', 'GPE'),\n ('the Chinese Empire', 'GPE'),\n ('the District of Columbia', 'GPE'),\n ('the Philippine Islands', 'GPE'),\n ('the United States', 'GPE')}"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the set of unique GPEs\n",
    "set(gpes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity\n",
    "\n",
    "Choose a method from the single document analysis portion of the workshop, and apply it to this small corpus. For example, you could find the most common words, create a cleaned corpus, or aggregate parts of speech. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy also provides a `pipe` method on the language model that will process texts in a stream. This can be useful for larger collections of texts, especially along with disabling parts of the pipeline you aren't using. \n",
    "\n",
    "https://spacy.io/api/language#pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 56s, sys: 8.38 s, total: 3min 5s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%time docs = [nlp(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.4 s, sys: 7.18 s, total: 47.6 s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%time docs = list(nlp.pipe(texts, batch_size=10, n_process=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources for spaCy\n",
    "\n",
    "- [spaCy 101](https://spacy.io/usage/spacy-101) - spaCy's own intro documentation\n",
    "- [Advanced NLP with spaCy](https://course.spacy.io/) - spaCy's own interactive learning course; you don't need to be \"ready\" for \"advanced\" work to benefit from going through this course\n",
    "- [textacy](https://github.com/chartbeat-labs/textacy) - a Python library built on top of spaCy and scikit-learn to faciliate working with a corpus and providing extra functionality\n",
    "- [spaCy universe](https://spacy.io/universe) - extensive collection of packages built on top of or with spaCy for various NLP and text analysis tasks\n",
    "- [spaCy youtube videos](https://www.youtube.com/c/ExplosionAI/videos) - Explosion has a lot of great videos on Youtube, and there are a number of other folks who have created great walkthroughs of using different parts of spaCy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('ODSC_text_analysis': venv)",
   "language": "python",
   "name": "python390jvsc74a57bd0d85925e9d69664fb980567a43066fabbbc365891912da785e2ea0194b03e21b9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}